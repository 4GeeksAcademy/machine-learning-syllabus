{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_applications_exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Code Running and Study**"
      ],
      "metadata": {
        "id": "KJKMqEHHGyVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 80% of a **ML/DL Engineers/Scientists'** activity is picking up, study, reuse and assembly others' repositories and codes, in order to improve them and adapt them to our own case/situation, or to create some enhancements in that direction integrating the code with other codes. **Nobody** will build code/models/algorithms from scratch in real life, demanding applications. It is a useless waste of time. What everybody needs is that you take their code and improve it, with your ideas, this is the **Democratization of AI**, this is the main reason of the great breakthroughs in AI in recent years. You must always start from state-of-art in terms of code and methodology, and keep going from that point onwards. \n",
        "\n",
        "Run and Analyze the following codes within the folder **deep_learning_app_week_13:** \n",
        "\n",
        "**deep_learning_computer_vision_engine**.**zip**\n",
        "\n",
        "**intrusion_detection**.**zip**\n",
        "\n",
        "**lp_detection_backend**.**zip**\n",
        "\n",
        "Link all the paths within the configuration files to the datasets which are: \n",
        "\n",
        "**dataset_characters.zip**\n",
        "\n",
        "**EuroSAT.zip**\n",
        "\n",
        "**Intrusion_Detection_DS.zip**\n",
        "\n",
        "1) Train for 100 epochs each one\n",
        "\n",
        "2) If needed run with Colab GPUs or TPUs: so learn to convert the Mains of this code into Colab.\n",
        "\n",
        "*Hint:* zip training sets and libraries sets and upload on google drive or github (it is another way) and download them with:\n",
        "!git clone repo.git on colab\n",
        "\n",
        "Pay attention: on Github each file cannot exceed 100Mb, so do not zip datasets and libraries if you choose github.com as source. \n",
        "\n",
        "Analyze the code: \n",
        "\n",
        "1) What are the novelties within these codes? \n",
        "\n",
        "2) How are models and classes structured? Explain\n",
        "\n",
        "Learn to study and analyze others' codes, to identify structures, techniques, methodologies, functions and classes...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "frplGgdKG_Ky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1wCySB0Gt2J"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}