# -*- coding: utf-8 -*-
"""class_activation_map_for_visualizing_cnns.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18-3p6OY66BBJFZgOJ64wdhTQIXm5nVC0

#**All Imports**

We disable the eager-execution constrain form tf2 with the compat mode for tf1 to calculate gradients for one layer
"""

import os
import cv2
import timeit
import platform
import numpy as np
import matplotlib.pyplot as plt

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras import backend as K
from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input, decode_predictions
import tensorflow as tf
tf.compat.v1.disable_eager_execution()

"""#**Visualizing heatmaps of activations: Class Activation Map (CAM)**

Another very interesting Convnets internals visualization technique is useful for understanding which parts of a given image led a convnet to its final classification decision. This is very iportant to understand the decision process of a convnet, and it is very useful in case of a classification error. It also allows you to locate specific objects in an image.

This visualization technique is called **"Class Activation Map" (CAM)** visualization and yields heatmaps of "class activation" over input images. A "class activation" heatmap is a 2D grid of scores associated with an specific output class, computed for every location in any input image, indicating how important each location is with respect to the class considered, it is something very related to **Segmentation** (that we will see very soon). 

The implementation consists in taking the output feature map of a convolution layer given an input image, and weighing every channel in that feature map by the gradient of the class with respect to the channel. Intuitively, one way to understand this trick is that we are weighting a spatial map of "how intensely the input image activates different channels" by "how important each channel is with regard to the class", resulting in a spatial map of "how intensely the input image activates the class".

![download (1).jfif](data:image/jpeg;base64,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)

#**All Utility Functions Definition**
"""

def data_download(file_to_download, gdrive_code, OS, uncompress = True):
  if not os.path.exists(file_to_download):
    os.system('gdown --id "'+gdrive_code+'" --output '+file_to_download)
    if OS == "Linux" and uncompress:
        os.system('unzip -o -n "./'+file_to_download+'" -d "./"')
    return True
  else: 
    return None

"""# **All Downloads**"""

start_time = timeit.default_timer()
# Operating System
OS = platform.system()                           # returns 'Windows', 'Linux', etc

os.system('pip install --upgrade --no-cache-dir gdown')

out = data_download("./elephants.zip", "1lAjqVPXqgstb6XdhBHtmoDs78PRGeByc", OS)

print("Elapsed Time: ", timeit.default_timer() - start_time)

"""# **Initializations**

**K.clear_session()** is useful when you're creating multiple models, such as during hyperparameter search or cross-validation. Each model you train adds nodes (potentially numbering in the thousands) to the graph. TensorFlow executes the entire graph whenever you call tf.Session.run() or tf.Tensor.eval(), so your models will become slower and slower to train, and you may also run out of memory. Clearing the session removes all the nodes left over from previous models, freeing memory and preventing slowdown.
"""

K.clear_session()

"""# **Model Definition**

This time, we are including the fully-connected layers on top
"""

model = VGG16(weights='imagenet')

"""# **Data Preparation**

`img` is a PIL image of size 224x224

`x` is a float32 Numpy array of shape (224, 224, 3)

We add a dimension to transform our array into a "batch"  of size (1, 224, 224, 3)

Finally we preprocess the batch (this does channel-wise color normalization)

**preprocess_input:** Preprocessed numpy.array or a tf.Tensor with type float32.
The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling.
"""

img_path = './elephants.jfif'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

"""The **top-3** probabilities for this image are:

**African elephant** (with 90.9% probability)

**Tusker** (with 8.6% probability)

**Indian elephan**t (with 0.4% probability)

Thus our network has recognized our image as containing an undetermined quantity of African elephants. The entry in the prediction vector that was maximally activated is the one corresponding to the "African elephant" class:

**decode_predictions**: A list of lists of top class prediction tuples (class_name, class_description, score). One list of tuples per sample in batch input.
"""

preds = model.predict(x)
print('Predicted:', decode_predictions(preds, top=3)[0])

"""Let's take the index with maxmum likelihood: """

np.argmax(preds[0])

"""which is the output at the index 386

Let's use the **Grad-CAM** algorithm in order to check which part of the image belongs to an elephant:

1) Get the "african elephant" entry in the prediction vector

2) Get the output feature map of the `block5_conv3` layer, that is the last convolutional layer in VGG16

3) Calculate the gradient "**grads**" of the "african elephant" class with regard to the output feature map of `block5_conv3`

4) Calculate a vector of shape (512,), where each entry is the mean intensity of the gradient over a specific feature map channel

5) Adopt a function allowing us to access the values of the quantities we just defined: `pooled_grads` and the output feature map of `block5_conv3`, given a sample image

6) Determine the values of these two quantities, as Numpy arrays, given our sample image of two elephants

7) Nultiply each channel in the feature map array by "how important this channel is" with regard to the elephant class

8) Calculate the channel-wise mean of the resulting feature map, is our heatmap of class activation

**Grad-CAM Algorithm** - Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., & Batra, D. (2017). Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision (pp. 618-626).
"""

african_elephant_output = model.output[:, 386]
last_conv_layer = model.get_layer('block5_conv3')
grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]
pooled_grads = K.mean(grads, axis=(0, 1, 2))
iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])
pooled_grads_value, conv_layer_output_value = iterate([x])
for i in range(512):
    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]
heatmap = np.mean(conv_layer_output_value, axis=-1)

"""Heatmap normalization between 0 and 1:"""

heatmap = np.maximum(heatmap, 0)
heatmap /= np.max(heatmap)
plt.matshow(heatmap)
plt.show()

"""We use cv2 to load the original image"""

img = cv2.imread(img_path)

"""We resize the heatmap to adapt it to the original image, namely to have the same size"""

heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))

"""We convert the heatmap to RGB"""

heatmap = np.uint8(255 * heatmap)

"""We apply the heatmap to the original image"""

heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

"""0.4 here is a heatmap intensity factor"""

superimposed_img = heatmap * 0.4 + img

"""Save the image to isk

"""

cv2.imwrite('./elephant_cam.jpg', superimposed_img)

"""Let's show the resulting image"""

from google.colab.patches import cv2_imshow
cv2_imshow(superimposed_img)

"""#**Homework**

1) Retrain all layers of VGG16 (or another model if you are able) on garbage and dogs datasets and plot Class Activation Map for two test set images: 1 correctly classified and 1 wrongly classified.

2) Check the difference of CAM for re-trained VGG16 (pretrained in transfer learning on IMAGENET) with all layers retrained and for VGG16 only trained in the last dense layers
"""

