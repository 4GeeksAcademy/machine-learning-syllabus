# -*- coding: utf-8 -*-
"""numpy_pandas_introduction_day_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eBy-ZVSIR-2r3lhPl7nFtuenKY6AWznN

# Introduction to Data Analysis with Python


<img src="https://www.python.org/static/img/python-logo.png" alt="yogen" style="width: 200px; float: right;"/>
<br>
<br>
<br>

## `pandas`

### Getting started with pandas
"""

import pandas as pd
import numpy as np

"""### `pandas` data structures

### Series

The base pandas abstraction. You can thing of it as the love child of a numpy array and a dictionary.
"""

s = pd.Series([4, 7, -5, 3])
s

"""If we provide an index, pandas will use it. If not, it will automatically create one."""

print(s.index)
print(s.values)

list('ifneurh')

s2 = pd.Series([1, 2, 4.5, 7, 2, 23, 15], index=['i', 'f', 'n', 'e', 'u', 'r', 'h'])
s2

s2['r']

s2 > 3

s2[s2>3]









evens = s2 % 2 == 0

s2[evens]

s2 * 2

np.exp(s2)

'f' in s2

clase = pd.Series([34, 22, 45, 72], index=['Toni', 'Fulanito', 'Menganito', 'Victor'])

clase[clase==22].index

"""We can create Series from dictionaries:"""

sdata = {'B' : 3e6, 'M': 6e6, 'P': 1.2e5, 'V': 7e5}

s3 = pd.Series(sdata)
s3

increase = {'M': 4e5, 'B' : 2e5, 'Z': -2e4}

s4 = pd.Series(increase)

"""And here is where the magic happens: numpy arrays only identify their contents by position. In contrast, pandas knows their "name" and will align them based on their indexes:"""

s3.values

s4.values

s3.values + s4.values

s3 + s4

s3.name = 'population_2000'
s3.index.name = 'province'

s3







"""### DataFrame

This is the object you'll work most of the time with. It represents a table of _m_ observations x _n_ variables. Each variable, or column, is a Series.
"""

dfdata = {
    'province' : ['M', 'M', 'M', 'B', 'B'],
    'population': [1.5e6, 2e6, 3e6, 5e5, 1.5e6],
    'year' : [1900, 1950, 2000, 1900, 2000]   
}

df = pd.DataFrame(dfdata)
df

df2 = pd.DataFrame(dfdata, columns=['province','population', 'year', 'debt'])
df2

df2.index

df2.columns

df2[['population','province']]

df2.population

df2['2nd_language']=list('EEFFG')

df2['2nd_language'] = np.nan

df2.index = [list('EEFFG')]

df2



df2['2nd_language']

df2.2nd_language

# df2['abs']

df2.index = list('abcde')

df2

df2.loc['a']

df2['debt'] = 10
df2

df2['debt'] = [1,0,2,.5,.7]
df2

df2['capital'] = df2['province'] == 'M'
df2

df2.T

df2

df2.describe()

df2.describe().T

"""### Index objects

Indexes are immutable.
"""

df2.index[1] = 'x'

df2.index[1]

df2.iloc[2:]



"""### Dropping entries from an axis"""

s5 = pd.Series(np.arange(5), list('jduvk'))
s5

s6 = s5.drop(['d','k'])
s6

s5

s5.drop(['d','k'],inplace=False)

s5

"""By default, `drop()` doesn't modify the original Series- it creates a copy. We can change that with the argument `inplace`."""

s5

s6['u'] = 7
s5

df2

df2.drop('c')

df2

df2.drop('c', axis=0)

df2.drop('2nd_language', axis=1)

df3 = df2.drop('2nd_language', axis=1)

df3

df4 = df3

df4.drop(['a','b'],inplace=True)

df4

df3







df3 = df2.copy()
df3

df3.drop('capital', axis=1, inplace=True)
df3

df2

"""### Indexing, selection, and filtering

The key here is that we can build boolean Series that we can use to index the original Series or DataFrame. Those booleans can be combined with bitwise boolean operators (&, |, ~) to get filters that are as complex as we need. 
"""

s3

s3[['V', 'M']]

s3[2:]

s3['P':'V']

s3 > 1e06

s3[s3>1e06]

df3

df3[df3['year'] > 1950]

df3[(df3['year'] > 1900) & (df3['debt'] > 1)]

recent = df3['year'] > 1900
indebted = df3['debt'] > 1

df3[recent & indebted]

df3[df3['year'] > 1900][df3['debt'] > 1]

"""### Function application and mapping

Function application and mapping allows us to modify the elements of a DataFrame (columns with apply or elements with applymap) without for loops. This way we are not constrained to the functions already implemented by pandas or numpy.
"""

df3

np.sqrt(df3['population'])

df4 = pd.DataFrame(np.random.randn(4,3) * 17 + 15, columns=list('bde'), index=list('BMPZ'))
df4

np.abs(df4)

"""This is a typical use case for lambdas (anonymous functions)"""

df4.apply(lambda series: series.max() - series.min())

df4.applymap(lambda element: element % 10 )

df4.apply(lambda series: series.max() - series.min(), axis=1)

def f(series):
    return pd.Series([series.max(), series.min()], index=['max', 'min'])

df4.apply(f)

for item in df4.items():
    print(item)

for item in df4.iteritems():
    print(item)

map(f, [1,2])

def format_2digits(number):
    return '%.2f' % number

df4.applymap(format_2digits)

"""### Sorting and ranking"""

df4.sort_index(ascending=False)

df4.sort_index(ascending=False, axis=1)

df4.sort_values(by='e')

df4.sort_values(by=['e','b'])

s1 = pd.Series([2,3,8,4,3,2,1], index=list('abcdefg'))
s1

s1.sort_values()

"""rank() returns the positions of the elements of the Series in its sorted version. If there are ties, it will take averages."""

s1.rank()

pd.Series([1,1,1]).rank()

s2 = pd.Series([30,10,20], index=list('abc'))
s2

s2.rank()

help(s2.rank)

"""# Exercise 1

Write a function that takes a Series and returns the top 10% registers. In this case, earners. Test it with this Series:

```python
salaries = pd.Series([150000, 90000, 120000,30000,10000,5000,40000, 50000, 80000, 35000, 27000,14000, 28000, 22000,25000])
```

# Exercise 2
"""

salaries = pd.Series([150000, 90000, 120000,30000,10000,5000,40000, 50000, 80000, 35000, 27000,14000, 28000, 22000,25000])

def top_earners(serie):
    number_to_extract = round(len(serie) / 10)
    return salaries.sort_values()[-number_to_extract:]

top_earners(salaries)

def top_earners(serie, percentile=0.9):
    is_top_earner = serie.rank(pct=True) > percentile
    return serie[is_top_earner]

print(top_earners(salaries))
print(top_earners(salaries, .8))

"""## Summarizing and computing descriptive statistics"""

x = pd.Series([1.2, np.nan, 4, np.nan, 9], index=list('abcde'))
y = pd.Series([5, 3, 7, np.nan, 14], index=list('abcde'))

df = pd.DataFrame([x, y], index=['x','y']).T
df

df.sum()

"""As with many methods, we can use them in the direction perpendicular to their default."""

df.sum(axis=1)

pd.__version__

df.sum(axis=1, skipna=False)

df.mean()

df.mean(axis=1)

df.cumsum()

df.std()

df.describe()

df['x'].sum()

df['x'].describe()

"""### Unique values, value counts, and membership"""

s7 = pd.Series(list('gtcaaagcttcga'))
s7

s7.unique()

s7.value_counts()

puric_bases = ['a','g']
s7.isin(puric_bases)

s7[s7.isin(puric_bases)]

"""## Handling missing data"""

string_data = pd.Series(['Ma', 'Lu', 'Ca', 'Va', np.nan])
string_data

string_data[string_data!=np.nan]

"""This is weird... but it has some really good reasons. You can find explanations [here](https://stackoverflow.com/questions/10034149/why-is-nan-not-equal-to-nan) and [here](https://stackoverflow.com/questions/1565164/what-is-the-rationale-for-all-comparisons-returning-false-for-ieee754-nan-values)"""

np.nan == np.nan

string_data[~string_data.isnull()]

"""### Filtering out missing data"""

string_data[string_data.notnull()]

df5 = pd.DataFrame([[1,2,3], 
                    [np.nan, 8, 7], 
                    [4, np.nan, 90], 
                    [67,42,53]], 
                   columns=list('abc'))
df5

df5[df5['a'].notnull()]

df5.notnull()

"""any() and all() are functions of boolean Series. They reduce the Series to a single boolean value by applying repeatedly the operators "or" and "and", respectively."""

df5.notnull().any()

df5.notnull().all()

df5.isnull().any()

df5.dropna()

df5

df5.dropna(axis=1)

array = np.random.randn(8,3) * 20 + 100

df6 = pd.DataFrame(array, columns=list('xyz'), index=list('abcdefgh'))
df6.iloc[2:5, 1] = np.nan
df6.iloc[1:3, 2] = np.nan
df6

"""The thresh argument specifies the minimum number of non-null values required to keep a column (or row, with axis=1)"""

df6.dropna(thresh=2)

df6.dropna(thresh=2, axis=1)

df6.dropna(thresh=6, axis=1)

"""### Filling in missing data"""

df6.fillna(0)

df6.fillna({'x' : 100, 'y' : 50, 'z' : 20})

df6

df6.fillna(method='ffill')

df6.fillna(df6.median())

df6.median()

"""# Additional References

[Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do)

[What is SciPy?](https://www.scipy.org/)

[How can SciPy be fast if it is written in an interpreted language like Python?](https://www.scipy.org/scipylib/faq.html#how-can-scipy-be-fast-if-it-is-written-in-an-interpreted-language-like-python)

[What is the difference between NumPy and SciPy?](https://www.scipy.org/scipylib/faq.html#what-is-the-difference-between-numpy-and-scipy)

[Linear Algebra for AI](https://github.com/fastai/fastai/blob/master/tutorials/linalg_pytorch.ipynb)
"""