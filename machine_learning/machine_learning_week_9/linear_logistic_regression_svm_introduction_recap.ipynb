{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_logistic_regression_svm_introduction_recap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**First 3 Models in Traditional Machine Learning Recap**"
      ],
      "metadata": {
        "id": "4-7TWNw4YBsr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTXWRo2ACiD6"
      },
      "source": [
        "#**Linear Regression: Inputation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUcxOeuPm_JU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd67afe-ecbd-43ae-d595-36440eab9e71"
      },
      "source": [
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/linear_regression/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/linear_regression/test.csv')\n",
        "\n",
        "print(train_data.head())\n",
        "\n",
        "# shape of the dataset\n",
        "print('\\nShape of training data :',train_data.shape)\n",
        "print('\\nShape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Item_Outlet_Sales\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
        "train_y = train_data['Item_Outlet_Sales']\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "test_x = test_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
        "test_y = test_data['Item_Outlet_Sales']\n",
        "\n",
        "'''\n",
        "Create the object of the Linear Regression model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : fit_intercept and normalize\n",
        "Documentation of sklearn LinearRegression: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "\n",
        " '''\n",
        "model = LinearRegression()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# coefficeints of the trained model\n",
        "print('\\nCoefficient of model :', model.coef_)\n",
        "\n",
        "# intercept of the model\n",
        "print('\\nIntercept of model',model.intercept_)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('\\nItem_Outlet_Sales on training data',predict_train) \n",
        "\n",
        "# Root Mean Squared Error on training dataset\n",
        "rmse_train = mean_squared_error(train_y,predict_train)**(0.5)\n",
        "mean_absolute_percentage_error_train = mean_absolute_percentage_error(train_y,predict_train)\n",
        "print('\\nRMSE on train dataset : ', rmse_train)\n",
        "print('\\nMAPE on train dataset : ', mean_absolute_percentage_error_train)\n",
        "\n",
        "# predict the target on the testing dataset\n",
        "predict_test = model.predict(test_x)\n",
        "#print('\\nItem_Outlet_Sales on test data',predict_test) \n",
        "\n",
        "# Root Mean Squared Error on testing dataset\n",
        "rmse_test = mean_squared_error(test_y,predict_test)**(0.5)\n",
        "mean_absolute_percentage_error_test = mean_absolute_percentage_error(test_y,predict_test)\n",
        "print('\\nRMSE on test dataset : ', rmse_test)\n",
        "print('\\nMAPE on test dataset : ', mean_absolute_percentage_error_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Establishment_Year  \\\n",
            "0     6.800000         0.037490   48.6034                       2004   \n",
            "1    15.600000         0.172597  114.8518                       1997   \n",
            "2    12.911575         0.054721  107.8254                       1985   \n",
            "3    11.800000         0.098312   81.4618                       1998   \n",
            "4    17.850000         0.046600  125.1388                       2004   \n",
            "\n",
            "   Item_Outlet_Sales  Item_Fat_Content_LF  Item_Fat_Content_Low Fat  \\\n",
            "0           291.6204                    0                         1   \n",
            "1          2163.1842                    0                         1   \n",
            "2          2387.5588                    0                         1   \n",
            "3           161.1236                    0                         1   \n",
            "4          1981.4208                    0                         0   \n",
            "\n",
            "   Item_Fat_Content_Regular  Item_Fat_Content_low fat  Item_Fat_Content_reg  \\\n",
            "0                         0                         0                     0   \n",
            "1                         0                         0                     0   \n",
            "2                         0                         0                     0   \n",
            "3                         0                         0                     0   \n",
            "4                         1                         0                     0   \n",
            "\n",
            "   ...  Outlet_Size_High  Outlet_Size_Medium  Outlet_Size_Small  \\\n",
            "0  ...                 0                   0                  1   \n",
            "1  ...                 0                   0                  1   \n",
            "2  ...                 0                   1                  0   \n",
            "3  ...                 0                   0                  0   \n",
            "4  ...                 0                   0                  1   \n",
            "\n",
            "   Outlet_Location_Type_Tier 1  Outlet_Location_Type_Tier 2  \\\n",
            "0                            0                            1   \n",
            "1                            1                            0   \n",
            "2                            0                            0   \n",
            "3                            0                            0   \n",
            "4                            0                            1   \n",
            "\n",
            "   Outlet_Location_Type_Tier 3  Outlet_Type_Grocery Store  \\\n",
            "0                            0                          0   \n",
            "1                            0                          0   \n",
            "2                            1                          0   \n",
            "3                            1                          1   \n",
            "4                            0                          0   \n",
            "\n",
            "   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
            "0                              1                              0   \n",
            "1                              1                              0   \n",
            "2                              0                              0   \n",
            "3                              0                              0   \n",
            "4                              1                              0   \n",
            "\n",
            "   Outlet_Type_Supermarket Type3  \n",
            "0                              0  \n",
            "1                              0  \n",
            "2                              1  \n",
            "3                              0  \n",
            "4                              0  \n",
            "\n",
            "[5 rows x 36 columns]\n",
            "\n",
            "Shape of training data : (1364, 36)\n",
            "\n",
            "Shape of testing data : (341, 36)\n",
            "\n",
            "Coefficient of model : [-3.84197604e+00  9.83065945e+00  1.61711856e+01  6.09197622e+01\n",
            " -8.64161561e+01  1.23593376e+02  2.34714039e+02 -2.44597425e+02\n",
            " -2.72938329e+01 -8.09611456e+00 -3.01147840e+02  1.70727611e+02\n",
            " -5.40194744e+01  7.34248834e+01  1.70313375e+00 -5.07701615e+01\n",
            "  1.63553657e+02 -5.85286125e+01  1.04913492e+02 -6.01944874e+01\n",
            "  1.98948206e+02 -1.40959023e+02  1.19426257e+02  2.66382669e+01\n",
            " -1.85619792e+02  1.43925357e+03  2.16134663e+02  3.54723990e+01\n",
            "  3.54832996e+02 -5.54559635e+00 -3.49287400e+02 -1.39202954e+03\n",
            " -2.57982359e+02 -9.59016062e+02  2.60902796e+03]\n",
            "\n",
            "Intercept of model -121926.97473298304\n",
            "\n",
            "Item_Outlet_Sales on training data [ 803.88817641 1733.98835979 3294.52154482 ...  811.16967914 2343.96927185\n",
            " 2444.98869913]\n",
            "\n",
            "RMSE on train dataset :  1135.8159344155247\n",
            "\n",
            "MAPE on train dataset :  1.0610109532863097\n",
            "\n",
            "RMSE on test dataset :  1009.2517232209715\n",
            "\n",
            "MAPE on test dataset :  0.901275806780379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCMG4xn2DYE2"
      },
      "source": [
        "# **Logistic Regression: Titanic surviving prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPDL5lQtDfdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67995c03-c34a-4e9d-9c95-6e77a1f067f5"
      },
      "source": [
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/logistic_regression/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/logistic_regression/test.csv')\n",
        "\n",
        "\n",
        "print(train_data.head())\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the Logistic Regression model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : fit_intercept and penalty\n",
        "Documentation of sklearn LogisticRegression: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        " '''\n",
        "model = LogisticRegression()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# coefficeints of the trained model\n",
        "print('Coefficient of model :', model.coef_)\n",
        "\n",
        "# intercept of the model\n",
        "print('Intercept of model',model.intercept_)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('Target on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('Target on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Survived        Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
            "0         0  28.500000   7.2292         0         0         1           0   \n",
            "1         1  27.000000  10.5000         0         1         0           1   \n",
            "2         1  29.699118  16.1000         0         0         1           1   \n",
            "3         0  29.699118   0.0000         1         0         0           0   \n",
            "4         0  17.000000   8.6625         0         0         1           0   \n",
            "\n",
            "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
            "0         1        1        0  ...        1        0        0        0   \n",
            "1         0        1        0  ...        1        0        0        0   \n",
            "2         0        0        1  ...        1        0        0        0   \n",
            "3         1        1        0  ...        1        0        0        0   \n",
            "4         1        1        0  ...        1        0        0        0   \n",
            "\n",
            "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
            "0        0        0        0           1           0           0  \n",
            "1        0        0        0           0           0           1  \n",
            "2        0        0        0           0           0           1  \n",
            "3        0        0        0           0           0           1  \n",
            "4        0        0        0           0           0           1  \n",
            "\n",
            "[5 rows x 25 columns]\n",
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "Coefficient of model : [[-0.03112606  0.00155629  0.93299841  0.08451959 -1.02556785  1.24541941\n",
            "  -1.25346925  1.05047794  0.97898932  0.61562405 -1.14084292 -0.78091604\n",
            "  -0.28356149 -0.4478207   0.16173065  0.6339807  -0.04705229  0.20461808\n",
            "  -0.45766539 -0.33677639 -0.16688521  0.07948039  0.28573972 -0.37326995]]\n",
            "Intercept of model [0.07227482]\n",
            "Target on train data [0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
            " 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
            " 0 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 1\n",
            " 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1\n",
            " 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1\n",
            " 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0\n",
            " 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0\n",
            " 1 0 1 1 1 0 1 0 0]\n",
            "accuracy_score on train dataset :  0.8047752808988764\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1\n",
            " 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1]\n",
            "accuracy_score on test dataset :  0.8324022346368715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDa_2Q54HBFi"
      },
      "source": [
        "#**SVM: Titanic surviving prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8spONqJZHBS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b13135-152e-4d57-ae87-f2cbc2cf188c"
      },
      "source": [
        "# importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# read the train and test dataset\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/svm/train.csv')\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/vamsivarma/datasets/master/machine_learning/svm/test.csv')\n",
        "\n",
        "# shape of the dataset\n",
        "print('Shape of training data :',train_data.shape)\n",
        "print('Shape of testing data :',test_data.shape)\n",
        "\n",
        "# Now, we need to predict the missing target variable in the test data\n",
        "# target variable - Survived\n",
        "\n",
        "# seperate the independent and target variable on training data\n",
        "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
        "train_y = train_data['Survived']\n",
        "\n",
        "# seperate the independent and target variable on testing data\n",
        "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
        "test_y = test_data['Survived']\n",
        "\n",
        "'''\n",
        "Create the object of the Support Vector Classifier model\n",
        "You can also add other parameters and test your code here\n",
        "Some parameters are : kernal and degree\n",
        "Documentation of sklearn Support Vector Classifier: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        " '''\n",
        "model = SVC()\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(train_x,train_y)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(train_x)\n",
        "print('Target on train data',predict_train) \n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(train_y,predict_train)\n",
        "print('accuracy_score on train dataset : ', accuracy_train)\n",
        "\n",
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(test_x)\n",
        "print('Target on test data',predict_test) \n",
        "\n",
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(test_y,predict_test)\n",
        "print('accuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data : (712, 25)\n",
            "Shape of testing data : (179, 25)\n",
            "Target on train data [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0\n",
            " 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
            " 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
            " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            " 1 0 0 0 1 0 1 0 0]\n",
            "accuracy_score on train dataset :  0.651685393258427\n",
            "Target on test data [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
            " 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "accuracy_score on test dataset :  0.7262569832402235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework"
      ],
      "metadata": {
        "id": "txKqd54QdgRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Make Regressors with Support Vector Machines"
      ],
      "metadata": {
        "id": "50DiXwtGdjYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Apply this to predictive maintenance dataset \n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset\n"
      ],
      "metadata": {
        "id": "6rXw1S0RdrYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Try to flatten MNIST dataset like we do with MLP, so normalize with scikit learn (or divdide by 255) and classify with LR and SVC. And print Accuracy and see if it is better than MLP and CNNs.  "
      ],
      "metadata": {
        "id": "vO-wIQUpejPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ObkG0SxudiQR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}