{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_and_dl_recap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Artificial Intelligence and Deep Learning: Recap**\n"
      ],
      "metadata": {
        "id": "qtC2hy_cX-EC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYbDyEPkLrM_"
      },
      "source": [
        "# Artificial Neural Networks \n",
        "\n",
        "Artificial Neuron vs Biological Neuron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yUllr4WLOSA"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/1220/1*SJPacPhP4KDEB1AdhOFy_Q.png\" alt=\"drawing\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv_J_eFGPuDe"
      },
      "source": [
        "## **Weights** **$w_i$**\n",
        "\n",
        "$ potential = bias + \\Sigma_{i=1}^n w_i \\cdot in_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8R8-_nbQ7iB"
      },
      "source": [
        "## **Activation $f(\\cdot)$**\n",
        "\n",
        "$out = f(potential)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WOB7jviHc8Q"
      },
      "source": [
        "### **Sigmoid:**\n",
        "$f(x) = \\frac{1}{1 + e^{-x}} \\in ]0, 1[$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7whym0RwGddw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "zoBPh10zGx83",
        "outputId": "70f15629-a4b8-4815-8414-a79ac2f742ae"
      },
      "source": [
        "activation_layer = Activation('sigmoid')\n",
        "x = tf.linspace(-30.0, 30.0, 100)\n",
        "y = activation_layer(x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "plt.plot(x, y)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqXFcVbwI6Um"
      },
      "source": [
        "### **Hypoerbolic tangent**\n",
        "$f(x) = \\tanh(x) \\in ]-1, 1[$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Gl81wje9HyUP",
        "outputId": "86213f8b-b66d-4ee2-ce94-2512a65442a6"
      },
      "source": [
        "activation_layer = Activation('tanh')\n",
        "x = tf.linspace(-30.0, 30.0, 100)\n",
        "y = activation_layer(x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "plt.plot(x, y)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAFlCAYAAABIu4TDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5TldX3n+ee7q/p3Ad0Npmh+o3QEjAa0DjGb7FggRMyZFTIxCW7mBGf09GRWM5tk5wcu55hZMs5okjNOZsZJ7BOZkB3XNmvGtTdBEdEa3UQMjYMi3bY0GEI3xa+qhvrV9fu9f9xvwaWoqv5xv/d+b9V9Ps6pU/f749b3zftUN6/+fD73+43MRJIkSa23ruoCJEmSOpVBTJIkqSIGMUmSpIoYxCRJkipiEJMkSaqIQUySJKki3VUXcDrOOeecvOSSS5p6jfHxcbZu3drUa3Qae1ou+1k+e1ou+1k+e1quVvXzwQcffD4zX7PUsVUZxC655BL279/f1GsMDAzQ39/f1Gt0GntaLvtZPntaLvtZPntarlb1MyKeWO6YU5OSJEkVMYhJkiRVxCAmSZJUEYOYJElSRQxikiRJFTGISZIkVcQgJkmSVBGDmCRJUkUMYpIkSRUpJYhFxJ0R8WxEfG+Z4xER/z4iDkfEdyPizXXHbo2IR4uvW8uoR5IkaTUoa0Tsj4EbVzj+TmBX8bUb+AOAiNgB/BbwE8A1wG9FxPaSapIkSWprpTxrMjO/HhGXrHDKTcCfZGYC90fEtojYCfQD92bmMEBE3Est0H2mjLokqd1lJpMz84xOzTA+NcfkzBxz88nsfDI3P8/sXDKXCQnzCUlSbL70/pd+VjX/Cct6+LlZ8tCzVZexptjTcj383CxXH5/hrM3rK6uhVQ/9Ph94sm77SLFvuf2vEhG7qY2m0dvby8DAQFMKXTA2Ntb0a3Qae1ou+1m+ZvV0PpNnJ5KjY/McGZ3nyNg8R0fnOTaVTM62X4Aq1YMPVF3B2mNPS9Wz/uu8dltXZddvVRBrWGbuAfYA9PX1ZbOflu4T7stnT8tlP8tXdk8zk33feYrf+dIhjr5w/KX9F+3YwpUXncEF2zfTs7GbrRu76dnYxdaN3Wxe30V31zq61wVdxde6CNYFRAQREEAE1F4tvK4J2se3v/1t3vzmN5/4RJ00e1qub3/72/zSO9/G1o3VxaFWXfkocGHd9gXFvqPUpifr9w+0qCZJaprvPPkCd/z5AR584hhvOO9M/snbL+Pyc8/ksh/pqfQv/VZ68fEurr7IZb9lsqflevHxrsr/PLbq6vuAD0bEXmoL81/MzMGIuAf413UL9H8G+FCLapKk0j0zMsnHvvR9/uu3j3JOz0Z+5+ffxM+/5QK61rXTWJWkdlFKEIuIz1Ab2TonIo5Q+yTkeoDM/EPgbuBngcPABPAPimPDEfHbwMKE9x0LC/clabU5Nj7Nz/7+NxidnOVX3/Y6PnDt6zhjU3WLgCW1v7I+NfmeExxP4APLHLsTuLOMOiSpSp/42mGOTUzzhQ/8NG+84Kyqy5G0CnhnfUkqwZFjE/zJN5/g5998gSFM0kkziElSCf7tl39ABPzGDT9adSmSVhGDmCQ16MBTI3z+oaO896cu4bxtm6suR9IqYhCTpAZ97Evf58xN6/lf3nZZ1aVIWmUMYpLUgL86/Dz/7QfP8YFrX8dZW/yEpKRTYxCTpNM0P5/8my9+n/O3beZXfvKSqsuRtAoZxCTpNP3Fw4M8fPRFfvOGH2XT+uqeVSdp9TKISdJpmJ2b5/e+fIjLzz2Dm68+v+pyJK1SBjFJOg0HB0d5YmiCX33b63x8kaTTZhCTpNNwcHAEgB+/cFvFlUhazQxiknQaDgyOsGVDFxfv2FJ1KZJWMYOYJJ2GA4MjXH7uGaxzWlJSAwxiknSKMpODgyNcsfPMqkuRtMoZxCTpFB194Tijk7MGMUkNM4hJ0ik68FRtof6V5xnEJDXGICZJp+jg4CgRcPm5Z1RdiqRVziAmSafo4OAIl5y9lS0buqsuRdIqZxCTpFN08OkRrnR9mKQSGMQk6RSMTs7wxNAEV+x0WlJS4wxiknQKDj09CuAnJiWVwiAmSadg4dFGBjFJZTCISdIpODA4wrYt69l51qaqS5G0BhjEJOkUHBgc5YpzzyTCRxtJapxBTJJO0tx8cuhpH20kqTwGMUk6SX8zNM7kzLx31JdUGoOYJJ2khUcbeesKSWUxiEnSSTo4OEL3uuCyH+mpuhRJa4RBTJJO0sHBES77kR42dndVXYqkNaKUIBYRN0bEoYg4HBG3LXH84xHxUPH1g4h4oe7YXN2xfWXUI0nNcGDQRxtJKlfDT6yNiC7gE8ANwBHggYjYl5kHFs7JzN+oO//XgKvrfsTxzLyq0TokqZmGx6d5ZmTKT0xKKlUZI2LXAIcz8/HMnAb2AjetcP57gM+UcF1JahnvqC+pGcoIYucDT9ZtHyn2vUpEXAxcCny1bvemiNgfEfdHxM0l1CNJpXs5iPmJSUnlaXhq8hTdAnwuM+fq9l2cmUcj4rXAVyPi4cx8bPEbI2I3sBugt7eXgYGBphY6NjbW9Gt0GntaLvtZvpV6+tXvTrFtY/Dw/m+2tqhVzN/R8tnTcrVDP8sIYkeBC+u2Lyj2LeUW4AP1OzLzaPH98YgYoLZ+7FVBLDP3AHsA+vr6sr+/v9G6VzQwMECzr9Fp7Gm57Gf5VurpRx/6Olddson+/mtaW9Qq5u9o+expudqhn2VMTT4A7IqISyNiA7Ww9apPP0bE5cB24Jt1+7ZHxMbi9TnATwEHFr9Xkqo0PTvPY8+NuT5MUukaHhHLzNmI+CBwD9AF3JmZj0TEHcD+zFwIZbcAezMz695+BfDJiJinFgo/Wv9pS0lqB4efHWNmLg1ikkpXyhqxzLwbuHvRvg8v2v6XS7zvr4A3llGDJDXL4IvHAbhox5aKK5G01nhnfUk6gaHxaQDO3rqh4kokrTUGMUk6geEiiO0wiEkqmUFMkk7g2Pg0G7rXsWWDz5iUVC6DmCSdwND4NGdv3UBEVF2KpDXGICZJJzA8Pu20pKSmMIhJ0gkYxCQ1i0FMkk7AICapWQxiknQCBjFJzWIQk6QVTM3OMTY16z3EJDWFQUySVnBsfAaA7QYxSU1gEJOkFQyNTwHeVV9ScxjEJGkFL99Vf2PFlUhaiwxikrQCH28kqZkMYpK0AoOYpGYyiEnSCobHp1kXsG3z+qpLkbQGGcQkaQVD49Ns37KBdet8zqSk8hnEJGkFx8anvXWFpKYxiEnSCoa8q76kJjKISdIKhsenvYeYpKYxiEnSCnzOpKRmMohJ0jLm5pMXJgxikprHICZJy3jx+Azz6T3EJDWPQUySljFcPGfSICapWQxikrSMobHaXfXP9jmTkprEICZJyzg2UQti27d6V31JzWEQk6RlDI07IiapuQxikrSM4TFHxCQ1l0FMkpYxPDFNz8ZuNnZ3VV2KpDWqlCAWETdGxKGIOBwRty1x/L0R8VxEPFR8vb/u2K0R8WjxdWsZ9UhSGbyZq6Rm6270B0REF/AJ4AbgCPBAROzLzAOLTv1sZn5w0Xt3AL8F9AEJPFi891ijdUlSowxikpqtjBGxa4DDmfl4Zk4De4GbTvK97wDuzczhInzdC9xYQk2S1LChMZ8zKam5yghi5wNP1m0fKfYt9vMR8d2I+FxEXHiK75Wkljs2Mc12g5ikJmp4avIk/b/AZzJzKiL+EXAXcN2p/ICI2A3sBujt7WVgYKD0IuuNjY01/Rqdxp6Wy36Wr76nmclzo5OMDz9jn0+Tv6Pls6flaod+lhHEjgIX1m1fUOx7SWYO1W3+EfA7de/tX/TegaUukpl7gD0AfX192d/fv9RppRkYGKDZ1+g09rRc9rN89T0dm5pl9p57uOry19H/ttdVW9gq5e9o+expudqhn2VMTT4A7IqISyNiA3ALsK/+hIjYWbf5LuBg8foe4GciYntEbAd+ptgnSZVauIeYi/UlNVPDI2KZORsRH6QWoLqAOzPzkYi4A9ifmfuAfxIR7wJmgWHgvcV7hyPit6mFOYA7MnO40ZokqVHDEwYxSc1XyhqxzLwbuHvRvg/Xvf4Q8KFl3nsncGcZdUhSWYbHpwCDmKTm8s76krSEoTGfMymp+QxikrSEYxM+Z1JS8xnEJGkJQ+PTbOhaR8/GVt3lR1InMohJ0hKGx2qPN4qIqkuRtIYZxCRpCT5nUlIrGMQkaQnDEwYxSc1nEJOkJTgiJqkVDGKStISFNWKS1EwGMUlaZGp2jtGpWc42iElqMoOYJC3ywsQMANsNYpKazCAmSYu8fFd9g5ik5jKISdIiw+M+8FtSaxjEJGmR4QmDmKTWMIhJ0iLDY1OAQUxS8xnEJGmR4fFpImDbFoOYpOYyiEnSIkPj02zfsoGudT5nUlJzGcQkaZFjE9Ns37K+6jIkdQCDmCQtMjQ2zdlbN1ZdhqQOYBCTpEV8zqSkVjGISdIixyam2dFjEJPUfAYxSaozP58cm5hhh5+YlNQCBjFJqvPi8Rnm5tOpSUktYRCTpDpDxeONznZqUlILGMQkqc6x4vFG252alNQCBjFJqjM05nMmJbWOQUyS6rx4vBgRM4hJagGDmCTVGTk+C8AZm7orrkRSJzCISVKd0ckZIqBng0FMUvOVEsQi4saIOBQRhyPitiWO/2ZEHIiI70bEfRFxcd2xuYh4qPjaV0Y9knS6RiZn6dnQzTof+C2pBRr+J19EdAGfAG4AjgAPRMS+zDxQd9p/B/oycyIi/jHwO8AvFceOZ+ZVjdYhSWUYnZx1WlJSy5QxInYNcDgzH8/MaWAvcFP9CZn5tcycKDbvBy4o4bqSVLrRyRnO2LS+6jIkdYgygtj5wJN120eKfct5H/DFuu1NEbE/Iu6PiJtLqEeSTpsjYpJaqaV/20TE3wf6gLfV7b44M49GxGuBr0bEw5n52BLv3Q3sBujt7WVgYKCptY6NjTX9Gp3GnpbLfpZvbGyMp54/zlkbw96WwN/R8tnTcrVDP8sIYkeBC+u2Lyj2vUJEXA/cDrwtM6cW9mfm0eL74xExAFwNvCqIZeYeYA9AX19f9vf3l1D68gYGBmj2NTqNPS2X/SzfwMAArE8uOW8b/f1XV13OqufvaPnsabnaoZ9lTE0+AOyKiEsjYgNwC/CKTz9GxNXAJ4F3Zeazdfu3R8TG4vU5wE8B9Yv8JamlnJqU1EoN/22TmbMR8UHgHqALuDMzH4mIO4D9mbkP+F2gB/i/IwLgbzPzXcAVwCcjYp5aKPzook9bSlLLZKaL9SW1VCn/7MvMu4G7F+37cN3r65d5318BbyyjBklq1Mw8zMylI2KSWsY760tSYWI2AThzsyNiklrDICZJheMzte9nOiImqUUMYpJUOF6MiDk1KalVDGKSVJiYrX13sb6kVjGISVLBETFJrWYQk6TCxEtBzBExSa1hEJOkwsJifUfEJLWKQUySCsdnkwjo2WAQk9QaBjFJKkzMJj0bulm3LqouRVKHMIhJUuH4rNOSklrLICZJhYmZdKG+pJYyiElS4fisz5mU1FoGMUkqTDg1KanFDGKSVKiNiDk1Kal1DGKSVDg+49SkpNYyiEkSkJnF1KQjYpJaxyAmScDU7Dxz6RoxSa1lEJMkYGSy9nyjMw1iklrIICZJwOjkLODUpKTWMohJEvVBzBExSa1jEJMkYLSYmnRETFIrGcQkCUfEJFXDICZJvDwiduZmR8QktY5BTJJwRExSNQxikgSMTM4SQM8Gg5ik1jGISRK1qclN3bBuXVRdiqQOYhCTJGpTk5u7DWGSWssgJknURsS2OCspqcVKCWIRcWNEHIqIwxFx2xLHN0bEZ4vj34qIS+qOfajYfygi3lFGPZJ0qhwRk1SFhoNYRHQBnwDeCVwJvCcirlx02vuAY5l5GfBx4GPFe68EbgHeANwI/Kfi50lSS41OzrJ5vUFMUmuVMSJ2DXA4Mx/PzGlgL3DTonNuAu4qXn8OeHtERLF/b2ZOZeYPgcPFz5OklnJqUlIVyghi5wNP1m0fKfYteU5mzgIvAmef5HslqemcmpRUhVXz77+I2A3sBujt7WVgYKCp1xsbG2v6NTqNPS2X/SxPZvLCxDTd29Oelsjf0fLZ03K1Qz/LCGJHgQvrti8o9i11zpGI6AbOAoZO8r0AZOYeYA9AX19f9vf3l1D68gYGBmj2NTqNPS2X/SzP5Mwcc/d8ibM2b7CnJfJ3tHz2tFzt0M8ypiYfAHZFxKURsYHa4vt9i87ZB9xavH438NXMzGL/LcWnKi8FdgF/XUJNknTSRornTLpYX1KrNTwilpmzEfFB4B6gC7gzMx+JiDuA/Zm5D/gU8H9GxGFgmFpYozjvT4EDwCzwgcyca7QmSToVC8+ZdI2YpFYrZY1YZt4N3L1o34frXk8Cv7DMez8CfKSMOiTpdCwEMT81KanVvLO+pI43ujA16YiYpBYziEnqeC+NiLlGTFKLGcQkdbyXR8QqLkRSxzGISep4LtaXVBWDmKSON/JSEKu4EEkdxyAmqeONTs7Qs7GbdeGImKTWMohJ6nijk7OcscnhMEmtZxCT1PFGJ2c4c9P6qsuQ1IEMYpI6niNikqpiEJPU8QxikqpiEJPU8UYnZzjDqUlJFTCISep4johJqopBTFLHqwUxR8QktZ5BTFJHm5yZY3pu3hExSZUwiEnqaAuPNzrTICapAgYxSR1t4YHfTk1KqoJBTFJHWxgRc2pSUhUMYpI62ogjYpIqZBCT1NEcEZNUJYOYpI728hoxg5ik1jOISepoL4+IOTUpqfUMYpI62kgRxHo2OiImqfUMYpI62ujkDD0bu+laF1WXIqkDGcQkdTSfMympSgYxSR1tdHLGICapMgYxSR3NB35LqpJBTFJHc2pSUpUMYpI6Wm1q0hExSdVoKIhFxI6IuDciHi2+b1/inKsi4psR8UhEfDcifqnu2B9HxA8j4qHi66pG6pGkUzU6OcuZjohJqkijI2K3Afdl5i7gvmJ7sQngVzLzDcCNwL+LiG11x/9ZZl5VfD3UYD2SdEpcIyapSo0GsZuAu4rXdwE3Lz4hM3+QmY8Wr58CngVe0+B1JalhkzNzTM/Nu0ZMUmUaDWK9mTlYvH4a6F3p5Ii4BtgAPFa3+yPFlOXHI2Jjg/VI0klbeLyRU5OSqhKZufIJEV8Bzl3i0O3AXZm5re7cY5n5qnVixbGdwABwa2beX7fvaWrhbA/wWGbescz7dwO7AXp7e9+yd+/elf/LGjQ2NkZPT09Tr9Fp7Gm57Gfjnh6f57ZvHGf3mzbyP5zXbU9LZj/LZ0/L1ap+XnvttQ9mZt9Sx074z8DMvH65YxHxTETszMzBIlQ9u8x5ZwJ/Ady+EMKKn70wmjYVEf8Z+Kcr1LGHWlijr68v+/v7T1R6QwYGBmj2NTqNPS2X/Wzcd558Ab7xl/zE1W+k/4pee1oy+1k+e1quduhno1OT+4Bbi9e3Al9YfEJEbAA+D/xJZn5u0bGdxfegtr7sew3WI0knbWFq0sX6kqrSaBD7KHBDRDwKXF9sExF9EfFHxTm/CPwd4L1L3Kbi0xHxMPAwcA7wrxqsR5JO2ujkDICL9SVVpqG/fTJzCHj7Evv3A+8vXv8X4L8s8/7rGrm+JDXi5RExg5ikanhnfUkda+SlETGnJiVVwyAmqWONHJ8hAno2OiImqRoGMUkda3himu1bNtC1LqouRVKHMohJ6ljD49Ns3+K0pKTqGMQkdayhsWnO3uoDPSRVxyAmqWMNj0+zY+uGqsuQ1MEMYpI61rGJaXb0GMQkVccgJqkjzc8nxyZm2LHFICapOgYxSR3pxeMzzM2nU5OSKmUQk9SRhsanATjbqUlJFTKISepIxyZqQWy7U5OSKmQQk9SRhsZqQcypSUlVMohJ6kjDTk1KagMGMUkdaXh8CnBqUlK1DGKSOtLw+AxbN3SxaX1X1aVI6mAGMUkdaXh8ypu5SqqcQUxSRxoan2aHz5mUVDGDmKSONDw+zdl+YlJSxQxikjrSsfFpF+pLqpxBTFLHyUyGxqe9dYWkyhnEJHWciek5pmbnvZmrpMoZxCR1nIWbuRrEJFXNICap47wUxFwjJqliBjFJHeelIOYaMUkVM4hJ6jhDC8+ZdGpSUsUMYpI6zsJzJl0jJqlqBjFJHWd4fIb1XUHPxu6qS5HU4QxikjrO8PgUO7ZuICKqLkVSh2soiEXEjoi4NyIeLb5vX+a8uYh4qPjaV7f/0oj4VkQcjojPRoTzBJKabtjnTEpqE42OiN0G3JeZu4D7iu2lHM/Mq4qvd9Xt/xjw8cy8DDgGvK/BeiTphIZ8zqSkNtFoELsJuKt4fRdw88m+MWpzAtcBnzud90vS6To2Ps12g5ikNtBoEOvNzMHi9dNA7zLnbYqI/RFxf0QshK2zgRcyc7bYPgKc32A9knRCjohJaheRmSufEPEV4NwlDt0O3JWZ2+rOPZaZr1onFhHnZ+bRiHgt8FXg7cCLwP3FtCQRcSHwxcz8sWXq2A3sBujt7X3L3r17T+a/77SNjY3R09PT1Gt0GntaLvt5embnk/d/eYKfu2w9N132yjBmT8tlP8tnT8vVqn5ee+21D2Zm31LHTvjZ7cy8frljEfFMROzMzMGI2Ak8u8zPOFp8fzwiBoCrgT8DtkVEdzEqdgFwdIU69gB7APr6+rK/v/9EpTdkYGCAZl+j09jTctnP0/PsyCR8+T7e8mOvp/+tF7/imD0tl/0snz0tVzv0s9GpyX3ArcXrW4EvLD4hIrZHxMbi9TnATwEHsjYU9zXg3Su9X5LKNOQDvyW1kUaD2EeBGyLiUeD6YpuI6IuIPyrOuQLYHxHfoRa8PpqZB4pj/wL4zYg4TG3N2KcarEeSVjRsEJPURhq6rXRmDlFb77V4/37g/cXrvwLeuMz7HweuaaQGSToVPmdSUjvxzvqSOsoxR8QktRGDmKSOMjQ+TQRs22IQk1Q9g5ikjjI8PsW2zevpWudzJiVVzyAmqaPUnjPpaJik9mAQk9RRDGKS2olBTFJHMYhJaicGMUkdpRbENlZdhiQBBjFJHWR+Pjk2MeM9xCS1DYOYpI4xMjnD3Hyy3SAmqU0YxCR1DO+qL6ndGMQkdQyfMymp3RjEJHWMoTGDmKT2YhCT1DGOTRjEJLUXg5ikjuHUpKR2YxCT1DGGxqbZuqGLTeu7qi5FkgCDmKQOMjw+xY4eR8MktQ+DmKSOMTwxw44tBjFJ7cMgJqljDI9PuT5MUlsxiEnqGMNjPmdSUnsxiEnqCJnJ0Pg0Z7tGTFIbMYhJ6gjHZ+aYmp1nu2vEJLURg5ikjrBwV32fMympnRjEJHUEb+YqqR0ZxCR1hJeCmGvEJLURg5ikjvBSEHONmKQ2YhCT1BEcEZPUjgxikjrC0Pg067uCMzZ2V12KJL3EICapIzw3OsXZWzcSEVWXIkkvaSiIRcSOiLg3Ih4tvm9f4pxrI+Khuq/JiLi5OPbHEfHDumNXNVKPJC3n0DMj7OrtqboMSXqFRkfEbgPuy8xdwH3F9itk5tcy86rMvAq4DpgAvlx3yj9bOJ6ZDzVYjyS9yuzcPD94Zowrdp5ZdSmS9AqNBrGbgLuK13cBN5/g/HcDX8zMiQavK0kn7fHnx5meneeKnWdUXYokvUKjQaw3MweL108DvSc4/xbgM4v2fSQivhsRH48In8YrqXQHB0cAuHLnWRVXIkmvFJm58gkRXwHOXeLQ7cBdmbmt7txjmfmqdWLFsZ3Ad4HzMnOmbt/TwAZgD/BYZt6xzPt3A7sBent737J3794T/Kc1ZmxsjJ4e15OUyZ6Wy36evM8emubev5nhD2/YQve65Rfr29Ny2c/y2dNytaqf11577YOZ2bfUsRN+jjszr1/uWEQ8ExE7M3OwCFXPrvCjfhH4/EIIK372wmjaVET8Z+CfrlDHHmphjb6+vuzv7z9R6Q0ZGBig2dfoNPa0XPbz5H3qsW/x+p3TXH/d/7jiefa0XPazfPa0XO3Qz0anJvcBtxavbwW+sMK572HRtGQR3oja58lvBr7XYD2S9CoHB0ddqC+pLTUaxD4K3BARjwLXF9tERF9E/NHCSRFxCXAh8N8Wvf/TEfEw8DBwDvCvGqxHkl7h2dFJnh+b4kqDmKQ21NAtpjNzCHj7Evv3A++v2/4b4PwlzruuketL0okcHBwFcERMUlvyzvqS1rSXPzFpEJPUfgxikta0g4MjnHfWJs7asr7qUiTpVQxikta0A0+NcOV5joZJak8GMUlr1uTMHI8/P+76MEltyyAmac169Jkx5ubTICapbRnEJK1ZCwv1DWKS2pVBTNKadWBwhC0burh4x5aqS5GkJRnEJK1ZBwZHuPzcM1i3wvMlJalKBjFJa1JmcnBwxGlJSW3NICZpTTr6wnFGJ2cNYpLamkFM0pp04KnijvreQ0xSGzOISVqTDg6OEgGXn3tG1aVI0rIMYpLWpIODI1xy9la2bOiuuhRJWpZBTNKadPDpEa7Y6WiYpPZmEJO05oxOzvDE0ARXulBfUpsziElacw49PQp4R31J7c8gJmnN8dFGklYLg5ikNefA4ChnbV7PzrM2VV2KJK3IICZpTZmYnuUrB5/h6ou2EeGjjSS1N4OYpDXlU9/4Ic+NTvFr111WdSmSdEIGMUlrxtDYFJ/8+uP8zJW9vOXiHVWXI0knZBCTtGb8h68e5vjMHP/8xsurLkWSTopBTNKa8LdDE3z6W0/wi30XctmP9FRdjiSdFIOYpDXh9758iK51wa9fv6vqUiTppBnEJK16Dx95kX3feYr3//Rr6T3TW1ZIWj0MYpJWtczko186yPYt6/lHb3tt1eVI0ikxiEla1b7+6PP85eEhfu26XZyxaX3V5UjSKemuugBJOh2ZyVe//ywf/sIjXLhjM7/81ouqLkmSTplBTNKq84NnRvntPz/ANx59nte+Ziu/9ws/zsburqrLkqRT1tDUZET8QkQ8EhHzEdG3wnk3RsShiDgcEbfV7b80Ir5V7P9sRGxopB5Ja9ux8Wk+/IXv8c7f/wbfefIFPvx3r+SeX/87vPmi7VWXJkmnpdERse8Bfw/45HInRIXhCpMAAAchSURBVEQX8AngBuAI8EBE7MvMA8DHgI9n5t6I+EPgfcAfNFiTpFUqM5mYnmN8apaRyRkee26cQ0+PcuiZUX7w9Cg/fH6c+Ux++Scu5jdu+FF2bPXfbpJWt4aCWGYeBE70YN1rgMOZ+Xhx7l7gpog4CFwH/M/FeXcB/5I2CGKf+v9+yP/1zeP8/oG/rLqUNWXkRXtapnbrZ2bxfdHOBOYzyaydk8Dc/Dyz88ncfDI7l8zOzzMxNcf49Czz+eqffdGOLbz+3DN4xxvO5X/68fN4/blnNP8/SJJaoBVrxM4HnqzbPgL8BHA28EJmztbtP3+5HxIRu4HdAL29vQwMDDSlWIAn/naG9THHzPho067Riexpudqyn/GKb7XXAV11hyOgK2BdF6zrhq4IutbBxi7Y1L2ezV2wqTvY3B30bg3O27qOTd0BjAFjDH5/kMHvN6f8sbGxpv7d0mnsZ/nsabnaoZ8nDGIR8RXg3CUO3Z6ZXyi/pKVl5h5gD0BfX1/29/c37Vr9wMDAAM28Rieyp+Wyn+Wzp+Wyn+Wzp+Vqh36eMIhl5vUNXuMocGHd9gXFviFgW0R0F6NiC/slSZI6Qitu6PoAsKv4hOQG4BZgX2Ym8DXg3cV5twItG2GTJEmqWqO3r/i5iDgC/CTwFxFxT7H/vIi4G6AY7fogcA9wEPjTzHyk+BH/AvjNiDhMbc3YpxqpR5IkaTVp9FOTnwc+v8T+p4Cfrdu+G7h7ifMep/apSkmSpI7jsyYlSZIqYhCTJEmqiEFMkiSpIgYxSZKkihjEJEmSKmIQkyRJqohBTJIkqSIGMUmSpIoYxCRJkioStUc+ri4R8RzwRJMvcw7wfJOv0WnsabnsZ/nsabnsZ/nsabla1c+LM/M1Sx1YlUGsFSJif2b2VV3HWmJPy2U/y2dPy2U/y2dPy9UO/XRqUpIkqSIGMUmSpIoYxJa3p+oC1iB7Wi77WT57Wi77WT57Wq7K++kaMUmSpIo4IiZJklQRg9giEfHbEfHdiHgoIr4cEecV+yMi/n1EHC6Ov7nqWleDiPjdiPh+0bPPR8S2umMfKvp5KCLeUWWdq0lE/EJEPBIR8xHRt+iYPT0NEXFj0bPDEXFb1fWsRhFxZ0Q8GxHfq9u3IyLujYhHi+/bq6xxNYmICyPiaxFxoPjz/r8W++3paYqITRHx1xHxnaKn/0ex/9KI+Fbx5/+zEbGhlXUZxF7tdzPzTZl5FfDnwIeL/e8EdhVfu4E/qKi+1eZe4Mcy803AD4APAUTElcAtwBuAG4H/FBFdlVW5unwP+HvA1+t32tPTU/ToE9T+jF8JvKfopU7NH1P7vat3G3BfZu4C7iu2dXJmgf8tM68E3gp8oPi9tKenbwq4LjN/HLgKuDEi3gp8DPh4Zl4GHAPe18qiDGKLZOZI3eZWYGER3U3An2TN/cC2iNjZ8gJXmcz8cmbOFpv3AxcUr28C9mbmVGb+EDgMXFNFjatNZh7MzENLHLKnp+ca4HBmPp6Z08Bear3UKcjMrwPDi3bfBNxVvL4LuLmlRa1imTmYmd8uXo8CB4Hzsaenrfj/91ixub74SuA64HPF/pb31CC2hIj4SEQ8CfwyL4+InQ88WXfakWKfTt4/BL5YvLaf5bOnp8e+NU9vZg4Wr58GeqssZrWKiEuAq4FvYU8bEhFdEfEQ8Cy1GZvHgBfqBgxa/ue/I4NYRHwlIr63xNdNAJl5e2ZeCHwa+GC11ba/E/WzOOd2akPtn66u0tXjZHoqrSZZ+4i+H9M/RRHRA/wZ8OuLZmzs6WnIzLli6dEF1EbDL6+4JLqrLqAKmXn9SZ76aeBu4LeAo8CFdccuKPZ1vBP1MyLeC/xd4O358v1S7OcKTuF3tJ49PT32rXmeiYidmTlYLOV4tuqCVpOIWE8thH06M/9rsdueliAzX4iIrwE/SW2pUXcxKtbyP/8dOSK2kojYVbd5E/D94vU+4FeKT0++FXixbnhYy4iIG4F/DrwrMyfqDu0DbomIjRFxKbUPQfx1FTWuIfb09DwA7Co+ObWB2gce9lVc01qxD7i1eH0r8IUKa1lVIiKATwEHM/Pf1h2yp6cpIl6z8Mn9iNgM3EBt7d3XgHcXp7W8p97QdZGI+DPg9cA88ATwq5l5tPhD8R+pfSpoAvgHmbm/ukpXh4g4DGwEhopd92fmrxbHbqe2bmyW2rD7F5f+KaoXET8H/AfgNcALwEOZ+Y7imD09DRHxs8C/A7qAOzPzIxWXtOpExGeAfuAc4BlqMwn/D/CnwEXU/j79xcxcvKBfS4iInwa+ATxM7f9HAP87tXVi9vQ0RMSbqC3G76I2EPWnmXlHRLyW2od0dgD/Hfj7mTnVsroMYpIkSdVwalKSJKkiBjFJkqSKGMQkSZIqYhCTJEmqiEFMkiSpIgYxSZKkihjEJEmSKmIQkyRJqsj/D28iS/ZO+Jr8AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUQGYukFI_MO"
      },
      "source": [
        "### **Rectified Linear Unit (RELU)**\n",
        "$f(x) = max(0, x) \\in [0, \\rightarrow$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "pLajNOF3JGrV",
        "outputId": "6d309e83-924d-4629-c8a7-fd38acf11f2d"
      },
      "source": [
        "activation_layer = Activation('relu')\n",
        "x = tf.linspace(-3.0, 3.0, 100)\n",
        "y = activation_layer(x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "plt.plot(x, y)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4G4zDuaSReu"
      },
      "source": [
        "# **Artificial Neural Networks (Multilayer Perceptrons)**\n",
        "\n",
        "### **Layers**\n",
        "\n",
        "- Neurons are made of layers\n",
        "\n",
        "### **Network**\n",
        "\n",
        "- Layers are stacked into a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckjzFyBFS1KV"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/1280px-Artificial_neural_network.svg.png\" alt=\"drawing\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-nbAV8kUmr3"
      },
      "source": [
        "## **Training**\n",
        "\n",
        "### **Data Preparation**\n",
        "\n",
        "- Inputs must be numerical and in a pretty defined range\n",
        "\n",
        "  - Numbers should be normalized or standardized\n",
        "\n",
        "  - Pixel / Sound intensity are numbers\n",
        "\n",
        "  - Categorical data can be One-Hot encoded\n",
        "\n",
        "  - Texts (vocabulary) can be indexed (e.g. bag of words) or word embeddings are used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yJLMUKLVnCG"
      },
      "source": [
        "### **Stochastic Gradient Descent**\n",
        "\n",
        "- Forward Pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLhVVahvWZMt"
      },
      "source": [
        "<img src=\"https://thumbs.gfycat.com/ContentDarlingCub.webp\" alt=\"drawing\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTUV012-W3hl"
      },
      "source": [
        "- Backpropagation Pass\n",
        "\n",
        "<img src=\"https://thumbs.gfycat.com/HelpfulConstantKite-small.gif\" alt=\"drawing\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epw7g1c5Xq5N"
      },
      "source": [
        "### **Weight Updates**\n",
        "\n",
        "To make the learning process less chaotic and more stable, one may use:\n",
        "\n",
        "- Batch learning\n",
        "\n",
        "- Momentum\n",
        "\n",
        "- Learning Rate Decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvRN3aZiYUtU"
      },
      "source": [
        "## **Prediction**\n",
        "\n",
        "- To make a prediction, you just need the network topology and all the weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhj4qaybYjvk"
      },
      "source": [
        "<img src=\"https://thumbs.gfycat.com/AdorableJoyfulLemming.webp\" alt=\"drawing\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVVx8--ubC7n"
      },
      "source": [
        "# **Deep Learning Frameworks**\n",
        "\n",
        "[Which deep learning framework is the best?](https://towardsdatascience.com/which-deep-learning-framework-is-the-best-eb51431c39a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62f_Eo-QqGd"
      },
      "source": [
        "## **Keras**\n",
        "[Deep Learning for Humans](https://keras.io/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHJg23JaQbgb"
      },
      "source": [
        "## **Tensorflow**\n",
        "\n",
        "[An end-to-end open source machine learning platform](https://www.tensorflow.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP5N-v28REqL"
      },
      "source": [
        "## **Pytorch**\n",
        "[From research to production](https://pytorch.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Layers**\n",
        "\n",
        "Neural networks are organized in layers"
      ],
      "metadata": {
        "id": "LfwgOldDZbsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Perceptron**\n",
        "- The **perceptron** is the smallest neural network, with a single neuron.\n",
        "- It can do what a _Linear regression_ or a _Logistic Regression_ can do\n",
        "\n",
        "![classifier](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Perceptron_example.svg/1000px-Perceptron_example.svg.png)"
      ],
      "metadata": {
        "id": "R9QkEJUHYoJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dense Layers**\n",
        "\n",
        "Also called **Fully connected layers**\n",
        "\n",
        "- Fully connected layers are the normal at feedforward neural network layer.\n",
        "\n",
        "- These layers may have a nonlinear activation function or a softmax activation in order to output probabilities of class predictions. \n",
        "\n",
        "- Fully connected layers are used at the end of the network after feature extraction and consolidation has been performed by the convolutional and pooling layers.\n",
        "\n",
        "- They are used to create final nonlinear combinations of features and for making predictions by the network."
      ],
      "metadata": {
        "id": "7mMtixtXZlg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<img src=\"https://www.researchgate.net/profile/Martin-Cenek/publication/325067027/figure/fig5/AS:669059146342414@1536527539867/Illustration-of-the-multilayer-perceptron-artificial-neural-network-implementation-for.png\"/>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "Y_68Vj6MYpPp",
        "outputId": "aeb8745e-3593-4c93-8d2b-1083e7802cc2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://www.researchgate.net/profile/Martin-Cenek/publication/325067027/figure/fig5/AS:669059146342414@1536527539867/Illustration-of-the-multilayer-perceptron-artificial-neural-network-implementation-for.png\"/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([Dense(units=4, input_shape=[6], activation='relu'), layers.Dense(units=3, activation='relu'),  layers.Dense(units=1, activation=None)])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1lmbHAIYsvF",
        "outputId": "12a70776-b5bf-4a86-e88a-617cc7c91659"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 4)                 28        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 15        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47\n",
            "Trainable params: 47\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Layers\n",
        "\n",
        "- **Convolutional Neural Networks** are a powerful artificial neural network technique.\n",
        "\n",
        "- These networks preserve the spatial structure of the problem and were developed for object recognition tasks, such as handwritten digit recognition. \n",
        "\n",
        "- They are popular because people are achieving state-of-the-art results on difficult computer vision and natural language processing tasks.\n",
        "\n",
        "- **Convolutional layers** and **Pooling layers** and **Dense layers** are the buidling blocks of CNNs.\n",
        "\n",
        "- Advantages of CNNs over MLPs in the case of images:\n",
        "\n",
        "  - They use fewer parameters (weights) to learn than a fully connected\n",
        "  network.\n",
        "\n",
        "  - They are designed to be invariant to object position and distortion in\n",
        "  the scene.\n",
        "\n",
        "  - They automatically learn and generalize features from the input domain."
      ],
      "metadata": {
        "id": "hnUY5jNVas6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i0.wp.com/developersbreach.com/wp-content/uploads/2020/08/cnn_banner.png\" \n",
        "alt=\"drawing\" width=\"1000\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "-8Nj_mG_a85f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filters\n",
        "\n",
        "- The filters are essentially the neurons of the layer. \n",
        "\n",
        "- They have both weighted inputs and generate an output value like a neuron.\n",
        "\n",
        "- The input size is a fixed square called a _receptive field_.\n",
        "  \n",
        "  - If the convolutional layer is an input layer, then the input patch will be pixel values.\n",
        "  \n",
        "  - If they're deeper in the network architecture, then the convolutional layer will take input from a _feature map_ from the previous layer."
      ],
      "metadata": {
        "id": "6P0vZnOSbAO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/publication/316950618/figure/fig4/AS:495826810007552@1495225731123/The-receptive-field-of-each-convolution-layer-with-a-3-3-kernel-The-green-area-marks.png\" \n",
        "alt=\"drawing\" width=\"300\"/>\n"
      ],
      "metadata": {
        "id": "qzWoEnX5bDWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Maps\n",
        "\n",
        "- The _feature map_ is the output of one filter applied to the previous layer.\n",
        "\n",
        "- A given _filter_ is drawn across the entire previous layer and moved one pixel at a time. Each position results in an activation of the neuron and the output is collected in the _feature map_. \n",
        "\n",
        "- **Stride**: If the receptive field is moved one pixel from activation to activation, then the field will overlap with the previous activation. The distance that filter is moved across the input from the previous layer each activation is referred to as the stride. \n",
        "\n",
        "- **Padding**: If the size of the previous layer is not cleanly divisible by the size of the filter's receptive field and the size of the stride then it is possible for the receptive field to attempt to read off the edge of the input feature map. In this case, techniques like _zero padding_ can be used to invent mock inputs with zero values for the receptive field to read."
      ],
      "metadata": {
        "id": "DJYKGyoMbFe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/max/790/1*1okwhewf5KCtIPaFib4XaA.gif\" \n",
        "alt=\"drawing\" width=\"300\"/>"
      ],
      "metadata": {
        "id": "dOZcWe84bIDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling Layers\n",
        "\n",
        "- The pooling layers **down-sample** the previous layers feature map.\n",
        "\n",
        "- Pooling layers follow a sequence of one or more convolutional layers and are intended to **consolidate the features learned** and\n",
        "expressed in the previous layer's feature map.\n",
        "\n",
        "- As such, pooling may be considered a technique to **compress or generalize feature representations** and generally reduce the overfitting of the training data by the model.\n",
        "\n",
        "- Receptive field & Stride:\n",
        "\n",
        "  Their receptive field is much smaller than the convolutional layer.\n",
        "  \n",
        "  The stride is often equal to the size of the receptive field to avoid any overlap. \n",
        "  \n",
        "- Pooling layers are often very simple, taking\n",
        "the _average_ or the _maximum_ of the input value in order to create its own feature map."
      ],
      "metadata": {
        "id": "pVzHRCaubLo2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif\"\n",
        "alt=\"drawing\" width=\"500\"/>"
      ],
      "metadata": {
        "id": "wsH-Uvl5bNs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best practices\n",
        "\n",
        "- **Input Receptive Field Dimensions**: The default is 2D for images, but could be 1D such as for words in a sentence, signals in a time series or 3D for video that adds a time dimension.\n",
        "\n",
        "- **Receptive Field Size**: The patch should be as small as possible, but large enough to see features in the input data. It is common to use 3 x 3 on small images and 5 x 5 or 7 x 7 and more on larger image sizes.\n",
        "\n",
        "- **Stride Width**: Use the default stride of 1. It is easy to understand and you don't need padding to handle the receptive field falling off the edge of your images. This could be increased to 2 or larger for larger images.\n",
        "\n",
        "- **Number of Filters**: Filters are the feature detectors. Generally fewer filters are used at the input layer and increasingly more filters used at deeper layers.\n",
        "\n",
        "- **Padding**: Set to zero and called zero padding when reading non-input data. This is useful when you cannot or do not want to standardize input image sizes or when you want to use receptive field and stride sizes that do not neatly divide up the input image size.\n",
        "\n",
        "- **Pooling**: Pooling is a destructive or generalization process to reduce overfitting. Receptive field size is almost always set to 2 x 2 with a stride of 2 to discard 75% of the activations from the output of the previous layer.\n",
        "\n",
        "- **Data Preparation**: Consider standardizing input data, both the dimensions of the images and pixel values.\n",
        "\n",
        "- **Pattern Architecture**: It is common to pattern the layers in your network architecture. This might be one, two or some number of convolutional layers followed by a pooling layer. This structure can then be repeated one or more times. Finally, fully connected layers are\n",
        "often only used at the output end and may be stacked one, two or more deep.\n",
        "\n",
        "- **Dropout**: CNNs have a habit of overfitting, even with pooling layers. Dropout should be used such as between fully connected layers and perhaps after pooling layers."
      ],
      "metadata": {
        "id": "0iRkEG26bacV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent\n",
        "- Sample some training data, run it through the network to make predictions.\n",
        "\n",
        "- Measure the loss between the predictions and the true values.\n",
        "\n",
        "- Adjust the weights in a direction that makes the loss smaller.\n",
        "\n",
        "- Repeat until the loss is small enough / does not decrease anymore.\n"
      ],
      "metadata": {
        "id": "3SOiexgKb2IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<img src=\"https://i.imgur.com/rFI1tIk.gif\"/ width=\"100%\">"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "PRn9yXIPb6LK",
        "outputId": "f11618a7-611c-47fa-95e9-390675326d37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://i.imgur.com/rFI1tIk.gif\"/ width=\"100%\">"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Under- & overfitting**\n",
        "\n",
        "- A model with too little capacity underfits\n",
        "- A model with too much capacity might overfit\n",
        "\n",
        "![fitting](https://i.imgur.com/eUF6mfo.png)"
      ],
      "metadata": {
        "id": "Gwf-DDfncUBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Learning curves**\n",
        "\n",
        "The learning curves help the ML engineer, data scientist, to see when the model over- or underfits the training data.\n",
        "\n",
        "<img src=\"https://i.imgur.com/eP0gppr.png\" alt=\"drawing\" width=\"700\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "e6vweAdQctY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **State of the Art Architectures**"
      ],
      "metadata": {
        "id": "CJxwuW2zdReC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **For Images**\n",
        "\n",
        "these models were trained on heaps of images and won the ImageNet competition.\n",
        "\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2017/08/Sample-of-Images-from-the-ImageNet-Dataset-used-in-the-ILSVRC-Challenge.png\"/>"
      ],
      "metadata": {
        "id": "zNP_1CL5fiLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Oxford's [VGG](https://www.robots.ox.ac.uk/~vgg/research/very_deep/)\n",
        "\n",
        "<img src=\"https://vitalflux.com/wp-content/uploads/2021/11/VGG16-CNN-Architecture.png\" alt=\"drawing\" width=\"800\"/>"
      ],
      "metadata": {
        "id": "7JwhfntVfllU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVNgiMrtf4oR",
        "outputId": "d21112da-9c7e-41b9-e448-3a5dcfd36573"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 3s 0us/step\n",
            "553476096/553467096 [==============================] - 3s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google's [Inception](https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202)"
      ],
      "metadata": {
        "id": "DLpx_QeBgE8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://miro.medium.com/max/1024/1*cwR_ezx0jliDvVUV6yno5g.jpeg\"/>"
      ],
      "metadata": {
        "id": "Ufs4SehhgJsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://production-media.paperswithcode.com/methods/inceptionv3onc--oview_vjAbOfw.png\" alt=\"drawing\" width=\"1000\"/>"
      ],
      "metadata": {
        "id": "wwqnmdADg8VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "model = InceptionV3()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeImASJHgNV5",
        "outputId": "f0aa90d6-cbbd-4cbf-c260-941631edb4fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "96124928/96112376 [==============================] - 1s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation_3[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_4[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_8[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_13[0][0]',          \n",
            "                                                                  'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_15[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_20[0][0]',          \n",
            "                                                                  'activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_22[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_27[0][0]',          \n",
            "                                                                  'activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_29[0][0]',          \n",
            "                                                                  'activation_32[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_33[0][0]',          \n",
            "                                                                  'activation_36[0][0]',          \n",
            "                                                                  'activation_41[0][0]',          \n",
            "                                                                  'activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_43[0][0]',          \n",
            "                                                                  'activation_46[0][0]',          \n",
            "                                                                  'activation_51[0][0]',          \n",
            "                                                                  'activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_58[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_60[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_53[0][0]',          \n",
            "                                                                  'activation_56[0][0]',          \n",
            "                                                                  'activation_61[0][0]',          \n",
            "                                                                  'activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_68[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_63[0][0]',          \n",
            "                                                                  'activation_66[0][0]',          \n",
            "                                                                  'activation_71[0][0]',          \n",
            "                                                                  'activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_75[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_76[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_74[0][0]',          \n",
            "                                                                  'activation_78[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_81[0][0]',          \n",
            "                                                                  'activation_82[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_85[0][0]',          \n",
            "                                                                  'activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_79[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_87[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_90[0][0]',          \n",
            "                                                                  'activation_91[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_94[0][0]',          \n",
            "                                                                  'activation_95[0][0]']          \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_88[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_96[0][0]']          \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['mixed10[0][0]']                \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Microsoft's [ResNet](https://en.wikipedia.org/wiki/Residual_neural_network)\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/331364877/figure/fig3/AS:741856270901252@1553883726825/Left-ResNet50-architecture-Blocks-with-dotted-line-represents-modules-that-might-be.png\" alt=\"drawing\" width=\"800\"/>\n"
      ],
      "metadata": {
        "id": "9uuJ6VYnhl1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet import ResNet50\n",
        "model = ResNet50()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb9ZOabWaGrz",
        "outputId": "2d405d52-13fa-427e-e11c-a91fe609be6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "102981632/102967424 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,636,712\n",
            "Trainable params: 25,583,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **For Text**\n",
        "\n",
        "- feature-extraction (get the vector representation of a text)\n",
        "- fill-mask\n",
        "- ner (named entity recognition)\n",
        "- question-answering\n",
        "- sentiment-analysis\n",
        "- summarization\n",
        "- text-generation\n",
        "- translation\n",
        "- zero-shot-classification"
      ],
      "metadata": {
        "id": "6xfH29eKiQ9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transformers**\n",
        "\n",
        "- were introduced in 2017: [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)\n",
        "- took NLP by storm\n",
        "- might revolutionize the images sector as well [An image is worth 16 x 16 words](https://arxiv.org/pdf/2010.11929.pdf), 2020\n",
        "- [The illustrated transformer](https://jalammar.github.io/illustrated-transformer/)"
      ],
      "metadata": {
        "id": "aL1oSWYCjwLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Short history\n",
        "\n",
        "- GPT-like (also called auto-regressive Transformer models, generate text)\n",
        "- BERT-like (also called auto-encoding Transformer models, ingest text)\n",
        "- BART/T5-like (also called sequence-to-sequence Transformer models)\n",
        "\n",
        "![transformers](https://huggingface.co/course/static/chapter1/transformers_chrono.png)"
      ],
      "metadata": {
        "id": "KdYpp3stkjpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transfer learning**\n",
        "\n",
        "- More data, more parameters, that's the way to better transformers\n",
        "\n",
        "<img src=\"https://huggingface.co/course/static/chapter1/model_parameters.png\" alt=\"drawing\" width=\"800\"/>\n",
        "\n",
        "- Training such state-of-the-art models is expensive in time, resources, data, environmental impact\n",
        "\n",
        "![co2](https://huggingface.co/course/static/chapter1/carbon_footprint.png)\n",
        "\n",
        "- Transfer learning is like recycling existing models by fine-tuning them on your exact task.\n",
        "\n",
        "![recycling](https://www.chemietechnik.de/assets/images/3/zwischenablage01-296bf6a5-5f76a2f3.jpg)\n",
        "\n",
        "- [Big Science](https://bigscience.huggingface.co/): A one-year long research workshop on large multilingual models and datasets\n",
        "\n"
      ],
      "metadata": {
        "id": "r8o24lgzlBEK"
      }
    }
  ]
}