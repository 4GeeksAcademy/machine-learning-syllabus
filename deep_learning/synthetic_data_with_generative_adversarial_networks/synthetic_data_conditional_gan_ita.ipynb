{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOdCFauEVuGp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import platform\n",
        "# Operating System\n",
        "OS = platform.system()                                                             # returns 'Windows', 'Linux', etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1ybdcnwFsoX"
      },
      "source": [
        "# Libraries Installation Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez8yfeaNF4fq"
      },
      "source": [
        "Installation of all required libraries: SDGym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-D7vrLoFs_S",
        "outputId": "0f570d0f-1043-4440-ad24-2e20fb54654f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "os.system('pip install gdown')\n",
        "os.system('pip install sdgym')\n",
        "os.system('pip install pandas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItRx2G5iqCVe"
      },
      "source": [
        "# All Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCaLrZdtqEyt"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sdv.demo import load_tabular_demo\n",
        "from sdv.tabular import GaussianCopula, CTGAN, CopulaGAN\n",
        "from sdv.evaluation import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpWlXh4Sp9Tu"
      },
      "source": [
        "# All Globals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BkBAOfMnJgp"
      },
      "outputs": [],
      "source": [
        "benchmark = False\n",
        "#benchmark = True\n",
        "gaussian_copula_synth_model = False\n",
        "ctgan_synth_model = False\n",
        "copula_gan_synth_model = True\n",
        "#dataset = 'satgpa'\n",
        "dataset = 'acs'\n",
        "model_names = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esg7OV_Er08N"
      },
      "source": [
        "# All Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwAd3ykNr3mM"
      },
      "outputs": [],
      "source": [
        "start_global_time = timeit.default_timer()\n",
        "pd.set_option('display.max_columns', 500) \n",
        "pd.set_option('display.max_rows', 500) \n",
        "if ctgan_synth_model == True and copula_gan_synth_model == True: # Only one Gan \n",
        "  ctgan_synth_model = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouW2OiOXJ6Ey"
      },
      "source": [
        "# All Functions Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfElVjvcJ97x"
      },
      "outputs": [],
      "source": [
        "def explore_data(data): \n",
        "  print(\"\\nHead of Data: \\n\", data.head())\n",
        "  print(\"\\nTail of Data: \\n\", data.tail())\n",
        "  print(\"\\nShape of Data: \", data.shape)\n",
        "  print(\"\\nInformation about Data: \\n\")\n",
        "  try: \n",
        "    data.info()\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nTypes of Data attributes: \\n\")\n",
        "  try: \n",
        "    data.dtypes\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nSummary of all numerical fields in the dataset: \\n\")\n",
        "  try: \n",
        "    data.describe(include = [np.number])\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nSummary of all categorical fields in the dataset: \\n\")\n",
        "  try: \n",
        "    data.describe(include = ['O'])\n",
        "  except: \n",
        "    pass\n",
        "  print(\"\\nLoop Through Each Column and Check for nulls: \\n\")\n",
        "  try: \n",
        "    for i in range(len(data.columns)):\n",
        "        print(data.columns[i] + \": \" + str(data[data.columns[i]].isna().sum()))\n",
        "  except: \n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6RjXgJbqqjp"
      },
      "source": [
        "# Data Download - ACS and SatGPA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRaHeyccqra1"
      },
      "outputs": [],
      "source": [
        "if benchmark == True: \n",
        "  data = load_tabular_demo('student_placements')\n",
        "  n_to_generate = data.shape[0]\n",
        "else: \n",
        "  if dataset is 'satgpa':\n",
        "    if not os.path.exists(\"./satgpa.csv\"):\n",
        "      os.system('gdown --id \"1NNVF1LhBDkW_KKp5_QW8cAiQDFatzWMy\" --output \"./satgpa.csv\"')\n",
        "      data = pd.read_csv('./satgpa.csv')\n",
        "      data = data.drop(['sat_sum'], axis=1)\n",
        "      data.to_csv('satgpa_no_sum.csv', sep=',')\n",
        "      n_to_generate = data.shape[0]\n",
        "  elif dataset is 'acs':\n",
        "    if not os.path.exists(\"./acs_dataset.zip\"):\n",
        "      os.system('gdown --id \"1mKZfDieGBJP-cS-R7_i3zVKVawXThfUc\" --output \"./acs_dataset.zip\"')\n",
        "      if OS == \"Linux\":\n",
        "          os.system('unzip -o -n \"./acs_dataset.zip\" -d \"./\"')      \n",
        "      #data = pd.read_csv('./acs_dataset.csv')\n",
        "      #n_to_generate = data.shape[0]\n",
        "\n",
        "      data = pd.read_csv('./acs_dataset.csv', nrows = 1000)\n",
        "      n_to_generate = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z98uJzgjsIC1"
      },
      "source": [
        "# Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6rQLa3QsNr9",
        "outputId": "5f2d5512-bffc-42a7-f827-a9754be7d1a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Head of Data: \n",
            "    Unnamed: 0     PUMA  YEAR   HHWT  GQ  PERWT  SEX  AGE  MARST  RACE  HISPAN  \\\n",
            "0           0  17-1001  2012   88.0   1   61.0    1   21      6     1       0   \n",
            "1           1  17-1001  2012   61.0   1   85.0    1   21      6     1       0   \n",
            "2           2  17-1001  2012   54.0   1   54.0    1   21      6     1       0   \n",
            "3           3  17-1001  2012  106.0   1   69.0    1   21      6     1       0   \n",
            "4           4  17-1001  2012   31.0   1   56.0    1   21      6     1       0   \n",
            "\n",
            "   CITIZEN  SPEAKENG  HCOVANY  HCOVPRIV  HINSEMP  HINSCAID  HINSCARE  EDUC  \\\n",
            "0        0         3        1         1        1         1         1     7   \n",
            "1        0         4        1         1        1         1         1     2   \n",
            "2        0         3        2         2        1         1         1     7   \n",
            "3        0         3        2         2        2         1         1     7   \n",
            "4        0         3        2         2        2         1         1     6   \n",
            "\n",
            "   EMPSTAT  EMPSTATD  LABFORCE  WRKLSTWK  ABSENT  LOOKING  AVAILBLE  WRKRECAL  \\\n",
            "0        1        10         2         2       4        3         5         3   \n",
            "1        1        10         2         2       4        3         5         3   \n",
            "2        1        10         2         2       4        3         5         3   \n",
            "3        3        30         1         1       1        1         5         3   \n",
            "4        1        10         2         3       4        3         5         3   \n",
            "\n",
            "   WORKEDYR  INCTOT  INCWAGE  INCWELFR  INCINVST  INCEARN  POVERTY  DEPARTS  \\\n",
            "0         3   14000    14000         0         0    14000      118      902   \n",
            "1         3   18000        0         0         0    18000      262      732   \n",
            "2         3   14000    14000         0         0    14000      118      642   \n",
            "3         3    3800     3800         0         0     3800      262        0   \n",
            "4         3   14000    14000         0         0    14000      501        0   \n",
            "\n",
            "   ARRIVES  sim_individual_id  \n",
            "0      909                 12  \n",
            "1      744                 33  \n",
            "2      654                401  \n",
            "3        0                470  \n",
            "4        0                702  \n",
            "\n",
            "Tail of Data: \n",
            "      Unnamed: 0     PUMA  YEAR   HHWT  GQ  PERWT  SEX  AGE  MARST  RACE  \\\n",
            "995         995  17-1300  2012   74.0   1   96.0    1   22      6     1   \n",
            "996         996  17-1300  2012  126.0   1  162.0    1   22      6     1   \n",
            "997         997  17-1300  2012   78.0   1  101.0    1   22      6     1   \n",
            "998         998  17-1300  2012  114.0   1  111.0    1   22      6     1   \n",
            "999         999  17-1300  2012   33.0   1   34.0    1   22      6     1   \n",
            "\n",
            "     HISPAN  CITIZEN  SPEAKENG  HCOVANY  HCOVPRIV  HINSEMP  HINSCAID  \\\n",
            "995       0        0         3        2         2        2         1   \n",
            "996       0        0         3        2         2        2         1   \n",
            "997       0        0         3        1         1        1         1   \n",
            "998       0        0         3        1         1        1         1   \n",
            "999       0        0         3        2         2        1         1   \n",
            "\n",
            "     HINSCARE  EDUC  EMPSTAT  EMPSTATD  LABFORCE  WRKLSTWK  ABSENT  LOOKING  \\\n",
            "995         1     6        1        10         2         2       4        3   \n",
            "996         1    10        2        20         2         1       1        2   \n",
            "997         1     5        1        10         2         2       1        2   \n",
            "998         1     6        3        30         1         1       1        1   \n",
            "999         1     6        1        10         2         3       4        3   \n",
            "\n",
            "     AVAILBLE  WRKRECAL  WORKEDYR  INCTOT  INCWAGE  INCWELFR  INCINVST  \\\n",
            "995         5         3         3    7300     7300         0         0   \n",
            "996         4         3         1       0        0         0         0   \n",
            "997         4         3         3    6800     6800         0         0   \n",
            "998         4         3         3     200      200         0         0   \n",
            "999         5         3         3   16000    16000         0         0   \n",
            "\n",
            "     INCEARN  POVERTY  DEPARTS  ARRIVES  sim_individual_id  \n",
            "995     7300      101      732      809              58149  \n",
            "996        0      363        0        0              58161  \n",
            "997     6800      149     1035     1049              58342  \n",
            "998      200       16        0        0              58495  \n",
            "999    16000      135      502      524              58611  \n",
            "\n",
            "Shape of Data:  (1000, 37)\n",
            "\n",
            "Information about Data: \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 37 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Unnamed: 0         1000 non-null   int64  \n",
            " 1   PUMA               1000 non-null   object \n",
            " 2   YEAR               1000 non-null   int64  \n",
            " 3   HHWT               1000 non-null   float64\n",
            " 4   GQ                 1000 non-null   int64  \n",
            " 5   PERWT              1000 non-null   float64\n",
            " 6   SEX                1000 non-null   int64  \n",
            " 7   AGE                1000 non-null   int64  \n",
            " 8   MARST              1000 non-null   int64  \n",
            " 9   RACE               1000 non-null   int64  \n",
            " 10  HISPAN             1000 non-null   int64  \n",
            " 11  CITIZEN            1000 non-null   int64  \n",
            " 12  SPEAKENG           1000 non-null   int64  \n",
            " 13  HCOVANY            1000 non-null   int64  \n",
            " 14  HCOVPRIV           1000 non-null   int64  \n",
            " 15  HINSEMP            1000 non-null   int64  \n",
            " 16  HINSCAID           1000 non-null   int64  \n",
            " 17  HINSCARE           1000 non-null   int64  \n",
            " 18  EDUC               1000 non-null   int64  \n",
            " 19  EMPSTAT            1000 non-null   int64  \n",
            " 20  EMPSTATD           1000 non-null   int64  \n",
            " 21  LABFORCE           1000 non-null   int64  \n",
            " 22  WRKLSTWK           1000 non-null   int64  \n",
            " 23  ABSENT             1000 non-null   int64  \n",
            " 24  LOOKING            1000 non-null   int64  \n",
            " 25  AVAILBLE           1000 non-null   int64  \n",
            " 26  WRKRECAL           1000 non-null   int64  \n",
            " 27  WORKEDYR           1000 non-null   int64  \n",
            " 28  INCTOT             1000 non-null   int64  \n",
            " 29  INCWAGE            1000 non-null   int64  \n",
            " 30  INCWELFR           1000 non-null   int64  \n",
            " 31  INCINVST           1000 non-null   int64  \n",
            " 32  INCEARN            1000 non-null   int64  \n",
            " 33  POVERTY            1000 non-null   int64  \n",
            " 34  DEPARTS            1000 non-null   int64  \n",
            " 35  ARRIVES            1000 non-null   int64  \n",
            " 36  sim_individual_id  1000 non-null   int64  \n",
            "dtypes: float64(2), int64(34), object(1)\n",
            "memory usage: 289.2+ KB\n",
            "\n",
            "Types of Data attributes: \n",
            "\n",
            "\n",
            "Summary of all numerical fields in the dataset: \n",
            "\n",
            "\n",
            "Summary of all categorical fields in the dataset: \n",
            "\n",
            "\n",
            "Loop Through Each Column and Check for nulls: \n",
            "\n",
            "Unnamed: 0: 0\n",
            "PUMA: 0\n",
            "YEAR: 0\n",
            "HHWT: 0\n",
            "GQ: 0\n",
            "PERWT: 0\n",
            "SEX: 0\n",
            "AGE: 0\n",
            "MARST: 0\n",
            "RACE: 0\n",
            "HISPAN: 0\n",
            "CITIZEN: 0\n",
            "SPEAKENG: 0\n",
            "HCOVANY: 0\n",
            "HCOVPRIV: 0\n",
            "HINSEMP: 0\n",
            "HINSCAID: 0\n",
            "HINSCARE: 0\n",
            "EDUC: 0\n",
            "EMPSTAT: 0\n",
            "EMPSTATD: 0\n",
            "LABFORCE: 0\n",
            "WRKLSTWK: 0\n",
            "ABSENT: 0\n",
            "LOOKING: 0\n",
            "AVAILBLE: 0\n",
            "WRKRECAL: 0\n",
            "WORKEDYR: 0\n",
            "INCTOT: 0\n",
            "INCWAGE: 0\n",
            "INCWELFR: 0\n",
            "INCINVST: 0\n",
            "INCEARN: 0\n",
            "POVERTY: 0\n",
            "DEPARTS: 0\n",
            "ARRIVES: 0\n",
            "sim_individual_id: 0\n"
          ]
        }
      ],
      "source": [
        "explore_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi31R4QBEz_V"
      },
      "source": [
        "# Synthetic Data Generation via Gaussian Copula Method "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5VaMElMMSya"
      },
      "source": [
        "In mathematical terms, a copula is a distribution over the unit cube [0,1]d which is constructed from a multivariate normal distribution over Rd by using the probability integral transform. Intuitively, a copula is a mathematical function that allows us to describe the joint distribution of multiple random variables by analyzing the dependencies between their marginal distributions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UakSdALyDDcq"
      },
      "outputs": [],
      "source": [
        "if gaussian_copula_synth_model == True:\n",
        "  model = GaussianCopula()\n",
        "  model.fit(data)\n",
        "  model_names.append(dataset+'_gaussian_copula.pkl')\n",
        "  model.save(model_names[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqJjwF_kRHdf"
      },
      "source": [
        "# Synthetic Data Generation via Conditional GAN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivhaUFEiRXeF"
      },
      "source": [
        "Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design TGAN, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. TGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThtphOVcRSKB"
      },
      "outputs": [],
      "source": [
        "if ctgan_synth_model == True:\n",
        "  model = CTGAN(\n",
        "    epochs=500,\n",
        "    batch_size=100,\n",
        "    generator_dim=(256, 256, 256),\n",
        "    discriminator_dim=(256, 256, 256)\n",
        "  )\n",
        "  model.fit(data)\n",
        "  model_names.append(dataset+'_ctgan.pkl')\n",
        "  model.save(model_names[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic Data Generation via Copula GAN "
      ],
      "metadata": {
        "id": "Qc1f5o3yXpRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CopulaGAN model is a variation of the CTGAN Model which takes advantage of the CDF based transformation that the GaussianCopulas apply to make the underlying CTGAN model task of learning the data easier.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6VdYznSanO5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if copula_gan_synth_model == True:\n",
        "  model = CopulaGAN(\n",
        "    epochs=500,\n",
        "    batch_size=100,\n",
        "    generator_dim=(256, 256, 256),\n",
        "    discriminator_dim=(256, 256, 256)\n",
        "  )\n",
        "  model.fit(data)\n",
        "  model_names.append(dataset+'_copulagan.pkl')\n",
        "  model.save(model_names[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb-gXMC7mq9f",
        "outputId": "31f8cded-fffe-49c3-a4f5-5ed32d0a5559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_continuous_distns.py:5320: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return c**2 / (c**2 - n**2)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py:2606: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  Lhat = muhat - Shat*mu\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_continuous_distns.py:639: RuntimeWarning: invalid value encountered in sqrt\n",
            "  sk = 2*(b-a)*np.sqrt(a + b + 1) / (a + b + 2) / np.sqrt(a*b)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last ten iterations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The number of calls to function has reached maxfev = 600.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/_continuous_distns.py:5311: RuntimeWarning: divide by zero encountered in power\n",
            "  return cd2*x**(c-1)\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:43: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  a = (self.min - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:44: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  b = (self.max - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:43: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  a = (self.min - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/copulas/univariate/truncated_gaussian.py:44: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  b = (self.max - loc) / scale\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/minpack.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
            "  improvement from the last five Jacobian evaluations.\n",
            "  warnings.warn(msg, RuntimeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (3) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:148: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
            "  random_state=random_state).fit(X).labels_\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
            "  % (init + 1), ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhaartIlNulb"
      },
      "source": [
        "# Model Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6_ZCIS-M3oI"
      },
      "outputs": [],
      "source": [
        "model_file = []\n",
        "model_to_load = []\n",
        "if gaussian_copula_synth_model == True:\n",
        "  model_file.append(model_names[0])\n",
        "  model_to_load.append((\"GaussianCopula\", GaussianCopula))\n",
        "if ctgan_synth_model == True:\n",
        "  model_file.append(model_names[-1])\n",
        "  model_to_load.append((\"CTGAN\", CTGAN))\n",
        "elif copula_gan_synth_model == True:\n",
        "  model_file.append(model_names[-1])\n",
        "  model_to_load.append((\"COPULAGAN\", CopulaGAN))\n",
        "\n",
        "loaded_model = []\n",
        "for mf,ml in zip(model_file, model_to_load): \n",
        "  loaded_model.append((ml[0], ml[1].load(mf)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn0T8pLAa1aN"
      },
      "source": [
        "# Synthetic Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSjwsi4zMK2u"
      },
      "outputs": [],
      "source": [
        "synthetic_data = []\n",
        "for lm in loaded_model: \n",
        "  synthetic_data.append((lm[0], lm[1].sample(n_to_generate)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY_hj9EWKRLM"
      },
      "source": [
        "# Synthetic Data Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cEzGfEZKIWeV",
        "outputId": "ca310b54-3ef1-40aa-c369-8fbcc21e1a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Method:  COPULAGAN\n",
            "\n",
            "Head of Data: \n",
            "    Unnamed: 0     PUMA  YEAR   HHWT  GQ  PERWT  SEX  AGE  MARST  RACE  HISPAN  \\\n",
            "0         827  17-3407  2012  114.0   1   57.0    1   21      6     1       0   \n",
            "1         687  39-2800  2012   67.0   1  129.0    1   21      6     1       0   \n",
            "2         392  39-4000  2012   83.0   1  125.0    1   21      6     1       0   \n",
            "3         726   39-100  2012   10.0   1   14.0    1   21      6     1       0   \n",
            "4         880  17-3102  2012   40.0   1  103.0    1   21      6     1       0   \n",
            "\n",
            "   CITIZEN  SPEAKENG  HCOVANY  HCOVPRIV  HINSEMP  HINSCAID  HINSCARE  EDUC  \\\n",
            "0        0         3        1         2        2         1         1     6   \n",
            "1        0         3        2         2        1         1         1     7   \n",
            "2        0         3        2         2        1         1         1     6   \n",
            "3        0         3        2         2        2         1         1     6   \n",
            "4        0         3        2         2        2         1         1     5   \n",
            "\n",
            "   EMPSTAT  EMPSTATD  LABFORCE  WRKLSTWK  ABSENT  LOOKING  AVAILBLE  WRKRECAL  \\\n",
            "0        1        10         2         2       4        3         5         3   \n",
            "1        3        29         1         1       1        1         5         3   \n",
            "2        1        11         2         2       4        3         5         3   \n",
            "3        3        30         1         1       1        2         5         1   \n",
            "4        3        30         1         1       1        1         5         1   \n",
            "\n",
            "   WORKEDYR  INCTOT  INCWAGE  INCWELFR  INCINVST  INCEARN  POVERTY  DEPARTS  \\\n",
            "0         3    4953    29430         0        -3     2400      119     1046   \n",
            "1         3    4501        0         0        -4     1160        0       79   \n",
            "2         3    2417     2800         0         0     3970      482     1142   \n",
            "3         2     550        0         0         0      250      169        0   \n",
            "4         3       0        0         0         0        0        0       94   \n",
            "\n",
            "   ARRIVES  sim_individual_id  \n",
            "0     1255             297861  \n",
            "1        0             867211  \n",
            "2      580             970531  \n",
            "3        0            1096275  \n",
            "4        0            1155726  \n",
            "\n",
            "Tail of Data: \n",
            "      Unnamed: 0     PUMA  YEAR   HHWT  GQ  PERWT  SEX  AGE  MARST  RACE  \\\n",
            "995         491  39-4601  2012   48.0   1   22.0    1   21      6     1   \n",
            "996         611  17-3602  2012   67.0   1  236.0    1   21      6     1   \n",
            "997         766  39-2500  2012   69.0   1   10.0    1   21      6     1   \n",
            "998         781  39-5403  2012  195.0   1   13.0    1   21      6     1   \n",
            "999         954  17-1602  2012   57.0   1    2.0    1   21      6     1   \n",
            "\n",
            "     HISPAN  CITIZEN  SPEAKENG  HCOVANY  HCOVPRIV  HINSEMP  HINSCAID  \\\n",
            "995       0        0         3        2         1        2         1   \n",
            "996       0        0         3        2         2        2         1   \n",
            "997       0        0         3        2         2        2         1   \n",
            "998       0        0         3        2         2        2         1   \n",
            "999       0        0         3        2         2        2         1   \n",
            "\n",
            "     HINSCARE  EDUC  EMPSTAT  EMPSTATD  LABFORCE  WRKLSTWK  ABSENT  LOOKING  \\\n",
            "995         1     7        3        30         2         1       1        1   \n",
            "996         1     6        3        30         1         1       1        1   \n",
            "997         1     6        3        30         1         1       1        1   \n",
            "998         1     6        1        10         2         2       4        3   \n",
            "999         1     7        3        30         1         1       1        1   \n",
            "\n",
            "     AVAILBLE  WRKRECAL  WORKEDYR  INCTOT  INCWAGE  INCWELFR  INCINVST  \\\n",
            "995         5         1         3    8731     1380         0        -7   \n",
            "996         4         1         3    1503        0         0        -2   \n",
            "997         5         1         1    2036        0         0        10   \n",
            "998         5         3         3    1856     9850         0         1   \n",
            "999         5         3         1     278        0         0         0   \n",
            "\n",
            "     INCEARN  POVERTY  DEPARTS  ARRIVES  sim_individual_id  \n",
            "995     5740      283       50       13             887296  \n",
            "996        0        0       98        0            1103364  \n",
            "997        0       78        0        0            1253928  \n",
            "998     9290      501     1371      664             966679  \n",
            "999        0       15        1        0             897740  \n",
            "\n",
            "Shape of Data:  (1000, 37)\n",
            "\n",
            "Information about Data: \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 37 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Unnamed: 0         1000 non-null   int64  \n",
            " 1   PUMA               1000 non-null   object \n",
            " 2   YEAR               1000 non-null   int64  \n",
            " 3   HHWT               1000 non-null   float64\n",
            " 4   GQ                 1000 non-null   int64  \n",
            " 5   PERWT              1000 non-null   float64\n",
            " 6   SEX                1000 non-null   int64  \n",
            " 7   AGE                1000 non-null   int64  \n",
            " 8   MARST              1000 non-null   int64  \n",
            " 9   RACE               1000 non-null   int64  \n",
            " 10  HISPAN             1000 non-null   int64  \n",
            " 11  CITIZEN            1000 non-null   int64  \n",
            " 12  SPEAKENG           1000 non-null   int64  \n",
            " 13  HCOVANY            1000 non-null   int64  \n",
            " 14  HCOVPRIV           1000 non-null   int64  \n",
            " 15  HINSEMP            1000 non-null   int64  \n",
            " 16  HINSCAID           1000 non-null   int64  \n",
            " 17  HINSCARE           1000 non-null   int64  \n",
            " 18  EDUC               1000 non-null   int64  \n",
            " 19  EMPSTAT            1000 non-null   int64  \n",
            " 20  EMPSTATD           1000 non-null   int64  \n",
            " 21  LABFORCE           1000 non-null   int64  \n",
            " 22  WRKLSTWK           1000 non-null   int64  \n",
            " 23  ABSENT             1000 non-null   int64  \n",
            " 24  LOOKING            1000 non-null   int64  \n",
            " 25  AVAILBLE           1000 non-null   int64  \n",
            " 26  WRKRECAL           1000 non-null   int64  \n",
            " 27  WORKEDYR           1000 non-null   int64  \n",
            " 28  INCTOT             1000 non-null   int64  \n",
            " 29  INCWAGE            1000 non-null   int64  \n",
            " 30  INCWELFR           1000 non-null   int64  \n",
            " 31  INCINVST           1000 non-null   int64  \n",
            " 32  INCEARN            1000 non-null   int64  \n",
            " 33  POVERTY            1000 non-null   int64  \n",
            " 34  DEPARTS            1000 non-null   int64  \n",
            " 35  ARRIVES            1000 non-null   int64  \n",
            " 36  sim_individual_id  1000 non-null   int64  \n",
            "dtypes: float64(2), int64(34), object(1)\n",
            "memory usage: 289.2+ KB\n",
            "\n",
            "Types of Data attributes: \n",
            "\n",
            "\n",
            "Summary of all numerical fields in the dataset: \n",
            "\n",
            "\n",
            "Summary of all categorical fields in the dataset: \n",
            "\n",
            "\n",
            "Loop Through Each Column and Check for nulls: \n",
            "\n",
            "Unnamed: 0: 0\n",
            "PUMA: 0\n",
            "YEAR: 0\n",
            "HHWT: 0\n",
            "GQ: 0\n",
            "PERWT: 0\n",
            "SEX: 0\n",
            "AGE: 0\n",
            "MARST: 0\n",
            "RACE: 0\n",
            "HISPAN: 0\n",
            "CITIZEN: 0\n",
            "SPEAKENG: 0\n",
            "HCOVANY: 0\n",
            "HCOVPRIV: 0\n",
            "HINSEMP: 0\n",
            "HINSCAID: 0\n",
            "HINSCARE: 0\n",
            "EDUC: 0\n",
            "EMPSTAT: 0\n",
            "EMPSTATD: 0\n",
            "LABFORCE: 0\n",
            "WRKLSTWK: 0\n",
            "ABSENT: 0\n",
            "LOOKING: 0\n",
            "AVAILBLE: 0\n",
            "WRKRECAL: 0\n",
            "WORKEDYR: 0\n",
            "INCTOT: 0\n",
            "INCWAGE: 0\n",
            "INCWELFR: 0\n",
            "INCINVST: 0\n",
            "INCEARN: 0\n",
            "POVERTY: 0\n",
            "DEPARTS: 0\n",
            "ARRIVES: 0\n",
            "sim_individual_id: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36mmatch_library_callback\u001b[0;34m(info, size, data)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0;31m# Store the library controller if it is supported and selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_controller_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_make_controller_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                 \u001b[0minternal_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternal_api\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             )\n\u001b[1;32m    675\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib_controllers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_controller\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreading_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_threading_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchitecture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.7/dist-packages/numpy.libs/libopenblasp-r0-09e95953.3.13.so: cannot open shared object file: No such file or directory"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sdmetrics/base.py:97: RuntimeWarning: overflow encountered in exp\n",
            "  score = 1 / (1 + np.exp(-raw_score))\n",
            "/usr/local/lib/python3.7/dist-packages/sdmetrics/column_pairs/statistical/kl_divergence.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  real_data[pd.isna(real_data)] = 0.0\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3093: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._where(-key, value, inplace=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sdmetrics/column_pairs/statistical/kl_divergence.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  synthetic_data[pd.isna(synthetic_data)] = 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Score:  0.6209001577046215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sdmetrics/single_table/multi_column_pairs.py:76: RuntimeWarning: Mean of empty slice\n",
            "  return np.nanmean(values)\n"
          ]
        }
      ],
      "source": [
        "scored_and_synth_data = []\n",
        "for sd in synthetic_data:\n",
        "  try:\n",
        "    print(\"\\nMethod: \",sd[0])\n",
        "    explore_data(sd[1])\n",
        "    score = evaluate(sd[1], data)\n",
        "    print(\"\\n\\nScore: \", score)\n",
        "    scored_and_synth_data.append((sd[0], sd[1], score))  \n",
        "  except:\n",
        "    print(\"Error\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXRRKM9i4cft"
      },
      "outputs": [],
      "source": [
        "total_time = timeit.default_timer() - start_global_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CticH5Bsg-Y0"
      },
      "outputs": [],
      "source": [
        "for sas in scored_and_synth_data:\n",
        "  sas[1].to_csv(dataset+'_synth_data_generated_by_method_'+sas[0].lower()+'total_time_'+str(round(total_time,2))+'_score_'+str(round(sas[2],3))+'.csv', sep=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0DMKRkeqSJZ",
        "outputId": "c171583f-5536-4880-d2ec-ce14979117cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Exectution Time:  338.57483200799993\n"
          ]
        }
      ],
      "source": [
        "print(\"Global Exectution Time: \", total_time)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "gan_sdgym_istat_synt_challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}