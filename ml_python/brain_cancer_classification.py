# -*- coding: utf-8 -*-
"""brain_cancer_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l4bohFb98Fz2UIWW9Pk1oBRaQu6cAOJ6

#**Brain Cancer Classification**

#**All General Imports**
"""

# imports
import os
import sys
import timeit
import platform 
import numpy as np
import matplotlib.pyplot as plt
import cv2
import glob
from sklearn.model_selection import train_test_split

"""#**All Keras Imports**"""

from tensorflow.keras.models import save_model, Model, Sequential
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.layers import Input, Conv2D, Flatten, MaxPooling2D, Dropout, Dense, GlobalAveragePooling2D
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import array_to_img, img_to_array

"""#**All Functions Definitions**"""

def data_download(file_to_download, gdrive_code, OS, uncompress = True):
  if not os.path.exists(file_to_download):
    os.system('gdown --id "'+gdrive_code+'" --output '+file_to_download)
    if OS == "Linux" and uncompress:
        os.system('unzip -o -n "./'+file_to_download+'" -d "./"')
    return True
  else: 
    return None

"""#**All Data Downloads**"""

start_time = timeit.default_timer()
# Operating System
OS = platform.system()                           # returns 'Windows', 'Linux', etc

os.system('pip install --upgrade --no-cache-dir gdown')

out = data_download("./brain_tumor_dataset_1.zip", "1IlfIKVCF2nnYndfZWsE7NHPE0si2bof1", OS)
out = data_download("./brain_tumor_dataset_2.zip", "1dYZ4GMfSeCEdnw-JqlgNUsMajHzLCqWp", OS)
print("Elapsed Time: ", timeit.default_timer() - start_time)

"""#**Brain Tumor Classification**

#**All Globals**
"""

negative_dataset_path_1 = "./brain_tumor_dataset_1/no/"
positive_dataset_path_1 = "./brain_tumor_dataset_1/yes/"
negative_dataset_path_2 = "./brain_tumor_dataset_2/no/"
positive_dataset_path_2 = "./brain_tumor_dataset_2/yes/"

dataset_path = [positive_dataset_path_1, negative_dataset_path_1, positive_dataset_path_2, negative_dataset_path_2]
data_type = "float"

"""#**Hyperparameters**"""

neural_model = 'brain_net'
transfer_learning = True
epochs = 30
batch_size = 32
width = 256
height = 256
channels = 1
summary = True
val_set_rate = 0.1
test_set_rate = 0.1

"""#**Initializations**"""

np.random.seed(42)
dataset = []
labels = []

"""#**Preprocessing**"""

for dp in dataset_path:  
  images = glob.glob(dp + "*.jpg")
  images.sort()
  if "/yes" in dp: 
    label = 1               # tumor patient
  elif "/no" in dp: 
    label = 0               # healthy patient 
  for x in images:
    image = cv2.imread(x, cv2.IMREAD_GRAYSCALE)
    image = image / 255
    image = cv2.resize(image, (width, height))
    dataset.append(image)
    labels.append(label)

dataset = np.asarray(dataset).astype(data_type)
labels = np.asarray(labels).astype("int")
print("Dataset Shape: ", dataset.shape)
print("Labels Shape: ", labels.shape)

print(labels)

"""#**Data Shuffle**"""

indices = np.arange(dataset.shape[0])
np.random.shuffle(indices)
dataset = dataset[indices]
labels = labels[indices]

print(labels)

"""#**Dataset Sample Visualization**"""

fig = plt.figure(figsize=(10,5))
for i in range(15): 
    ax = fig.add_subplot(3, 5, 1 + i, xticks=[], yticks=[])
    ax.set_title(labels[i])
    plt.imshow(dataset[i], cmap = "gray")
plt.show()

"""#**Train-Val-Test Split**"""

train_x, val_x, train_y, val_y = train_test_split(dataset, labels, test_size=val_set_rate)
train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=test_set_rate)

print("Train X Shape: ", train_x.shape)
print("Train Y Shape: ", train_y.shape)
print("Val X Shape: ", val_x.shape)
print("Val Y Shape: ", val_y.shape)
print("Test X Shape: ", test_x.shape)
print("Test Y Shape: ", test_y.shape)

"""#**Model Definitions**"""

class AvancedBrainModel:
  
  @staticmethod
  def build(neural_model, transfer_learning, model_input_width, model_input_height, input_channels, summary):
      if transfer_learning is True: 
        pretrained_weights = "imagenet"
      else: 
        pretrained_weights = None
      
      if neural_model == 'xception':
          deep_network = Xception(weights=pretrained_weights, include_top=False, input_tensor=Input(shape=(model_input_width, model_input_height, input_channels)))
      elif neural_model == 'resnet':
          deep_network = ResNet50(weights=pretrained_weights, include_top=False, input_tensor=Input(shape=(model_input_width, model_input_height, input_channels)))
      elif neural_model.lower() == 'mobilenet':
          deep_network = MobileNet(weights=pretrained_weights, include_top=False, input_tensor=Input(shape=(model_input_width, model_input_height, input_channels)))
      elif neural_model.lower() == 'inceptionresnet':
          deep_network = InceptionResNetV2(weights=pretrained_weights, include_top=False, input_tensor=Input(shape=(model_input_width, model_input_height, input_channels)))
      elif neural_model.lower() == 'brain_net': 
          deep_network = Sequential()
          deep_network.add(Conv2D(32, 4, activation = 'relu', padding = 'same', input_shape=(model_input_width, model_input_height, input_channels)))
          deep_network.add(MaxPooling2D(pool_size=(2, 2)))
          deep_network.add(Dropout(0.5))
          deep_network.add(Conv2D(32, 4, activation = 'relu', padding = 'same'))
          deep_network.add(MaxPooling2D(pool_size=(2, 2)))
          deep_network.add(Dropout(0.3))
          deep_network.add(Conv2D(64, 4, activation = 'relu', padding = 'same'))
          deep_network.add(MaxPooling2D(pool_size=(2, 2)))
          deep_network.add(Dropout(0.3))
          deep_network.add(Flatten())
          deep_network.add(Dense(128, activation='relu'))
          deep_network.add(Dropout(0.15))
          deep_network.add(Dense(1, activation='sigmoid'))
      else: 
          print("Neural Model not supported: ", neural_model)
          return None    

      if neural_model.lower() != 'brain_net': 
        x = deep_network.output
        x = GlobalAveragePooling2D()(x)
        x = Dense(256,activation='relu')(x)
        x = Dropout(0.5)(x)
        predictions = Dense(1, activation='sigmoid')(x)

        deep_network = Model(inputs=deep_network.input, outputs=predictions)

      if summary==True:
          deep_network.summary()

      # return the constructed network architecture
      return deep_network

"""#**Brain Tumor Classifier Compiling**"""

brain_tumor_model = AvancedBrainModel.build(neural_model, transfer_learning, width, height, channels, summary)
brain_tumor_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

"""#**Brain Model Training**"""

history = brain_tumor_model.fit(train_x, train_y, validation_data = (val_x, val_y), epochs = epochs, batch_size = batch_size, verbose=1)

# save the model
save_model(brain_tumor_model, './brain_cancer_model.h5')

"""#**Brain Cancer Model Evaluation**"""

# list all data in history
print(history.history.keys())

# summarize history for accuracy
plt.plot(history.history['val_accuracy'])
plt.title('Validation Accuracy')
plt.ylabel('val accuracy')
plt.xlabel('epoch')
plt.legend(['train'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['val_loss'])
plt.title('Validation Loss')
plt.ylabel('val loss')
plt.xlabel('epoch')
plt.legend(['train'], loc='upper left')
plt.show()

score = brain_tumor_model.evaluate(test_x, test_y, verbose=0)
print('\n', 'Test accuracy:', score[1])

"""#**Inclass Exercises and Homeworks**

0) Make a pre and post Data Exploratory Analysis

1) Add all checkpoints to find the best model

2) Visualize internals of CNN with: Feature Map Visualization, Filter Visualization

3) Check if the model on some test images highlight the cancer with a segmentation-like process with Grad-Cam

4) Try to optimize the well-known models (resnet, inception, etc.) or the brain-net to get the best accuracy ever on the validation / test set

5) Train with TPU

6) Make some Data Augmentation and all needed regularizations

hints: try to flip horizontal and vertical flip, featurewise_std and samplewise_std, some small zoom, and other you find
"""

